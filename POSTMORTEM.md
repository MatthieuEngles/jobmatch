# Postmortem - JobMatch

## üìÖ Sessions

### 2026-01-05 (36) - Impl√©mentation Workflows CI/CD Multi-Environnement

**Contexte:** Suite de la session 35. Impl√©mentation concr√®te des workflows GitHub Actions pour une architecture multi-environnement (staging/prod) avec gestion s√©curis√©e des secrets via GCP Secret Manager.

**R√©alisations:**

- **Refonte terraform.yml** : Workflow multi-environnement automatis√©
  - D√©tection automatique d'environnement : `main` ‚Üí prod, `staging` ‚Üí staging
  - Plan + Apply automatique sur push vers main/staging
  - Plan only sur PR (commentaire dans la PR)
  - D√©clenchement manuel avec choix environnement/action
  - **Mise √† jour GitHub Variables** apr√®s apply : `GCS_BUCKET_PROD`, `VM_NAME_STAGING`, etc.
  - Changement `secrets.GCP_*` ‚Üí `vars.GCP_*` (identifiants, pas sensibles)

- **Refonte deploy.yml** : D√©ploiement s√©curis√© sans secrets
  - Support branches main et staging
  - Plus d'√©criture de secrets dans .env
  - Seules variables dans .env : `ENVIRONMENT=prod` et `GCP_PROJECT_ID`
  - Applications lisent secrets directement depuis Secret Manager √† runtime
  - VM_NAME dynamique depuis GitHub Variables (set par Terraform)
  - Branch checkout adapt√© √† l'environnement

- **Documentation mise √† jour** : `docs/multi_environnement_gestion.md`
  - Architecture Secret Manager avec lecture directe (jamais sur disque)
  - Code module `app/shared/secrets.py` pour lecture secrets
  - Workflows d√©taill√©s avec Option B (Terraform s√©par√©)
  - Checklist 7 phases pour impl√©mentation

**D√©cisions techniques cl√©s:**

| D√©cision | Justification |
|----------|---------------|
| Secrets JAMAIS sur disque | Principe "gros projet √† risque" - secrets lus at runtime |
| GitHub Variables vs Secrets | Terraform outputs (buckets, VM names) = non-sensibles ‚Üí Variables |
| Workflows s√©par√©s | terraform.yml pour infra, deploy.yml pour apps |
| Auto-apply on push | Simplifie le flow - "si c'est √† jour, au moins c'est automatique" |
| Workload Identity | Pas de credentials dans CI/CD |

**Architecture finale workflows:**

```
push to main/staging (infra changes)
       ‚Üì
  terraform.yml
       ‚Üì
  plan ‚Üí apply ‚Üí update GitHub Variables
                        ‚Üì
              GCS_BUCKET_PROD, VM_NAME_PROD, etc.

push to main/staging (app changes)
       ‚Üì
   deploy.yml
       ‚Üì
  reads GitHub Variables ‚Üê set by terraform.yml
       ‚Üì
  SSH to VM ‚Üí git pull ‚Üí docker compose up
       ‚Üì
  Apps read secrets from Secret Manager at runtime
```

**Fichiers modifi√©s:**
- `.github/workflows/terraform.yml` : Refonte compl√®te multi-env
- `.github/workflows/deploy.yml` : Refonte sans secrets, multi-env
- `docs/multi_environnement_gestion.md` : Architecture Secret Manager

**GitHub Variables √† cr√©er (via Settings > Variables):**
- `GCP_WORKLOAD_IDENTITY_PROVIDER` : projects/xxx/locations/global/...
- `GCP_SERVICE_ACCOUNT` : terraform@project.iam.gserviceaccount.com
- `GCP_PROJECT_ID` : job-match-v0
- Les autres (GCS_BUCKET_*, VM_NAME_*, etc.) seront cr√©√©es par Terraform

**Prochaines √©tapes:**
1. Cr√©er les GitHub Variables dans le repo
2. Cr√©er les secrets dans GCP Secret Manager (`jobmatch-{env}-{secret}`)
3. Impl√©menter `app/shared/secrets.py`
4. Ajouter Terraform outputs (gcs_bucket, vm_name, etc.)
5. Cr√©er branche staging et tester le flow complet

---

### 2026-01-05 (35) - Design Multi-Environnement Staging + Documentation Gestion Secrets

**Contexte:** Conception d'une architecture multi-environnement (local/dev/staging/prod) pour JobMatch avec focus sur la gestion des secrets et la d√©tection d'environnement par les services.

**R√©alisations:**

- **Documentation Multi-Environnement** : Cr√©ation de `docs/multi_environnement_gestion.md`
  - 3 approches pour la d√©tection d'environnement (ENV_MODE global, variables explicites, hybride)
  - Analyse d'impact par service (GUI, offre-ingestion, cv-ingestion, ai-assistant, matching)
  - Panorama complet de 9 techniques de gestion de secrets
  - Recommandations bas√©es sur les principes 12-Factor App
  - Workflows CI/CD avec GitHub Environments et GCP Secret Manager

- **Documentation Docker Compose** : Cr√©ation de `docs/docker_compose_guide.md`
  - Guide d'utilisation en fran√ßais
  - Section V1 vs V2 avec bug connu (panic slice bounds)

- **Audit Dockerfile Matching** : Cr√©√© `matthieu_perso/audit_matching_dockerfile.md`
  - 3 probl√®mes identifi√©s : contexte de build, incoh√©rence ports, chemins modules

- **Documentation S√©curit√©** : Cr√©ation de `docs/SECURITY_NOTES.md`
  - Faux positifs Bandit B608 (SQL injection) document√©s

- **Fixes mineurs** :
  - `app/gui/services/offers_db.py` ligne 240 : Ajout `from e` (ruff B904)
  - Script acc√®s GCP : `infra/scripts/add_gcp_access.sh` + `emails.txt`

**Probl√®mes identifi√©s (non r√©solus - discussion only):**

- **ENV_MODE seulement dans GUI** : Les autres services n'ont pas de notion d'environnement
- **Datasets hardcod√©s** : `offre-ingestion/transform_offers_to_bigquery_silver.py` ligne 91
  ```python
  DATASET_ID = "jobmatch_silver"  # HARDCODED - doit √™tre variable d'environnement
  ```
- **deploy.yml incomplet** : G√©n√®re .env sans variables GCP (buckets, datasets)

**D√©cisions techniques prises:**

- **Approche Hybride (Option C)** : ENV_MODE pour comportement + variables explicites pour ressources
- **GCP Secret Manager** : Recommand√© pour secrets (audit, rotation, versioning)
- **Terraform outputs** : Pour noms de ressources non-sensibles (buckets, datasets)
- **Workload Identity Federation** : D√©j√† en place, pas de secrets GCP √† g√©rer
- **√âtats Terraform s√©par√©s** : Un state par environnement (staging/prod)
- **VM staging s√©par√©e** : Option A retenue
- **Branche staging** : Depuis dev, pas depuis main

**Fichiers cr√©√©s:**
- `docs/multi_environnement_gestion.md` : Documentation principale (~800 lignes)
- `docs/docker_compose_guide.md` : Guide Docker Compose en fran√ßais
- `docs/SECURITY_NOTES.md` : Faux positifs Bandit
- `matthieu_perso/audit_matching_dockerfile.md` : Audit Dockerfile
- `infra/scripts/add_gcp_access.sh` : Script acc√®s GCP √©quipe
- `infra/scripts/emails.txt` : Template emails

**Prochaines √©tapes (√† impl√©menter plus tard):**
1. Ajouter ENV_MODE √† tous les services
2. Param√©trer datasets/buckets via variables d'environnement dans offre-ingestion
3. Configurer GitHub Environments (staging/production)
4. Cr√©er infrastructure staging avec Terraform
5. Mettre √† jour deploy.yml pour multi-environnement

---

### 2025-12-30 (34) - Top Offres : Correction Ajout Candidatures + Documentation Architecture

**Contexte:** Correction des bugs dans le flux d'ajout d'offres aux candidatures et cr√©ation de la documentation technique d'architecture du syst√®me Top Offres.

**R√©alisations:**

- **Fix ImportError** : Ajout de `ImportedOffer` aux imports dans `accounts/views.py` (ligne 36)
  - Erreur : `name 'ImportedOffer' is not defined`

- **Fix cr√©ation Application manquante** : Modification de `add_offer_to_applications_view`
  - Bug : L'offre √©tait import√©e (`ImportedOffer.objects.create()`) mais aucune `Application` n'√©tait cr√©√©e
  - Fix : Ajout de `Application.objects.create()` apr√®s la cr√©ation de l'ImportedOffer
  - L'utilisateur peut maintenant voir l'offre dans "Suivi des candidatures"

- **Fix rechargement sidebar** : Ajout de `window.location.reload()` dans le handler JS
  - Bug : Apr√®s ajout d'une offre, la carte "Suivi des candidatures" ne se mettait pas √† jour
  - Fix : Rechargement complet de la page apr√®s 1s (solution simple et efficace)

- **Documentation Architecture** : Cr√©ation de `docs/top_offers_architecture.md`
  - Sch√©ma flux utilisateur complet
  - Architecture mode mock (USE_MOCK_MATCHING=true) avec SQLite Silver DB
  - Architecture mode production avec BigQuery et matching API
  - Mod√®les de donn√©es (CandidateProfile, MatchResult, TopOfferResult, ImportedOffer, Application)
  - Endpoints API document√©s
  - Structure table BigQuery `gold.offers` avec colonnes embeddings

- **Export PDF** : G√©n√©ration de `docs/top_offers_architecture.pdf` via pandoc

**Probl√®mes rencontr√©s:**

- **Docker ContainerConfig KeyError** : Erreur r√©currente au rebuild
  - Solution : `docker rm -f <container_id>` puis `docker-compose up -d`

- **Offres non ajout√©es aux candidatures** :
  - Diagnostic : Query SQL confirmant ImportedOffer cr√©√© (id=13) mais Application manquante
  - Cause : `add_offer_to_applications_view` cr√©ait seulement ImportedOffer
  - Solution : Ajout de la cr√©ation d'Application dans la m√™me vue

**D√©cisions techniques:**

- **Deux embeddings s√©par√©s** : `title_embedding` (384 dims) + `cv_embedding` (384 dims)
  - title_embedding : g√©n√©r√© depuis profile.description ou profile.title
  - cv_embedding : g√©n√©r√© depuis les lignes CV s√©lectionn√©es du profil

- **Embeddings dans BigQuery** : Colonnes `ARRAY<FLOAT64>` dans `gold.offers` (pas de vector DB s√©par√©e)

- **Rechargement page** : Choisi plut√¥t qu'AJAX partiel pour simplicit√© et fiabilit√©

**Fichiers modifi√©s:**
- `app/gui/accounts/views.py` : Import ImportedOffer + cr√©ation Application
- `app/gui/templates/home.html` : Reload page apr√®s ajout offre
- `docs/top_offers_architecture.md` : Nouvelle documentation (cr√©√©)
- `docs/top_offers_architecture.pdf` : Export PDF (cr√©√©)

---

### 2025-12-29 (33) - Feature Top Offres Pour Vous (Design + Documentation)

**Contexte:** Ajout d'une nouvelle fonctionnalite permettant aux utilisateurs de rafraichir leurs recommandations d'offres d'emploi personnalisees.

**Realisations:**

- **Bouton Rafraichir** : Ajout du bouton dans la carte "Top offres pour vous" sur la homepage
  - CSS avec animation de rotation au survol
  - Structure HTML modifiee (`<a>` ‚Üí `<div>` + bouton separe)
  - ID `refresh-offers-btn` pour la future implementation JS

- **Documentation technique** : Creation de `doc_support_contexte/FEATURE_TOP_OFFERS.md`
  - Architecture complete du flux (GUI ‚Üí Shared ‚Üí Matching ‚Üí Gold DB)
  - Contrat API matching defini (POST `/api/match` avec embeddings + top_k)
  - Schemas de base de donnees Gold (embeddings + details)
  - Responsabilites par composant (Matthieu: GUI/Shared, Maxime: Matching)

**Decisions techniques:**

- **Gold DB unifie** : Les details des offres (intitule, description, entreprise) seront dans Gold DB (pas Silver)
- **Embeddings calcules cote GUI** : La GUI utilise `app/shared/` pour generer les embeddings avant d'appeler matching
- **API Matching simple** : Entree = 2 embeddings + top_k, Sortie = liste (offer_id, score)
- **Fusion multi-profils** : GUI fusionne les resultats de tous les profils, dedup par meilleur score

**Fichiers modifies:**
- `app/gui/templates/home.html` : Bouton rafraichir + CSS
- `doc_support_contexte/FEATURE_TOP_OFFERS.md` : Documentation complete (nouveau fichier)

**Prochaines etapes:**
1. Implementation du backend Django (endpoint AJAX)
2. Implementation du frontend JS (appel AJAX, loading state, affichage resultats)
3. Coordination avec Maxime pour l'API matching
4. Tests d'integration

---

### 2025-12-29 (32) - Ex√©cution Terraform + Configuration GitHub Secrets

**Contexte:** Suite de la session 31, ex√©cution du Terraform et r√©solution des probl√®mes de d√©ploiement.

**R√©alisations:**

- **Terraform apply r√©ussi** : Infrastructure GCP cr√©√©e (VM europe-west1, VPC, Storage, BigQuery, IAM)
- **Zone dynamique** : Ajout de `data.google_compute_zones.available` pour s√©lectionner automatiquement une zone disponible
- **Documentation enrichie** : Section d√©taill√©e configuration GitHub Secrets dans GCP_IAM_GUIDE.md avec erreur exacte et √©tapes pas √† pas
- **Workflow deploy.yml corrig√©** : R√©cup√©ration dynamique de la zone VM via `gcloud compute instances list`

**Probl√®mes rencontr√©s:**

- **VM unavailable europe-west9** :
  - Sympt√¥me : `e2-standard-2 is currently unavailable in europe-west9-b zone`
  - Solution : Changement r√©gion vers `europe-west1` (Belgique) + zone dynamique

- **BigQuery dataset "already exists"** :
  - Sympt√¥me : `Error 409: Already Exists: Dataset job-match-v0:jobmatch_gold`
  - Cause : Bug provider Google, dataset cr√©√© mais pas dans le state
  - Solution : `terraform import google_bigquery_dataset.gold job-match-v0/jobmatch_gold`

- **GitHub Actions "workload_identity_provider" error** :
  - Sympt√¥me : `google-github-actions/auth failed with: must specify exactly one of "workload_identity_provider" or "credentials_json"`
  - Cause : Secrets GitHub non configur√©s
  - Solution : Documenter la configuration compl√®te des secrets dans GCP_IAM_GUIDE.md

- **Terraform --classic snap** :
  - Sympt√¥me : `error: This revision of snap "terraform" was published using classic confinement`
  - Solution : `sudo snap install terraform --classic`

- **Application Default Credentials manquantes** :
  - Sympt√¥me : `storage.NewClient() failed: could not find default credentials`
  - Cause : `gcloud auth login` ‚â† `gcloud auth application-default login`
  - Solution : Ex√©cuter les deux commandes, documenter la diff√©rence

**D√©cisions techniques:**

- **europe-west1** au lieu de europe-west9 : Plus de disponibilit√© VM
- **Zone dynamique** : `data.google_compute_zones.available.names[0]` √©vite les erreurs de capacit√©
- **Deux types d'auth gcloud** : Documenter `auth login` (CLI) vs `auth application-default login` (SDK/Terraform)

**Fichiers modifi√©s:**
- `infra/terraform/vm.tf` : Ajout data source zones dynamique
- `infra/terraform/outputs.tf` : R√©f√©rences zone dynamique
- `infra/terraform/terraform.tfvars.example` : R√©gion europe-west1, suppression variable zone
- `.github/workflows/deploy.yml` : GCP_REGION + r√©cup√©ration zone dynamique
- `infra/docs/GCP_IAM_GUIDE.md` : Section d√©taill√©e GitHub Secrets

**Prochaines √©tapes:**
1. Configurer les secrets GitHub (voir GCP_IAM_GUIDE.md section A.3)
2. Donner acc√®s GCP √† Mohamed (Storage + BigQuery)
3. Int√©gration BigQuery dans offre-ingestion
4. D√©ploiement initial sur la VM

---

### 2025-12-29 (31) - Infrastructure Terraform GCP + CI/CD GitHub Actions

**Contexte:** Cr√©ation de l'infrastructure de d√©ploiement V0 sur Google Cloud Platform avec Terraform et CI/CD via GitHub Actions.

**R√©alisations:**

- **Documentation architecture** (`infra/docs/`) :
  - `ARCHITECTURE_V0.md` : Sch√©ma complet de l'infra (VM, VPC, Storage, BigQuery), estimation co√ªts (~32‚Ç¨/mois), flux de donn√©es, CI/CD
  - `GCP_IAM_GUIDE.md` : Guide complet gestion des droits IAM, Workload Identity Federation, ajout coll√®gues

- **Terraform complet** (`infra/terraform/`) :
  - `main.tf` : Provider GCP, backend GCS, activation APIs
  - `variables.tf` : Toutes les variables configurables
  - `network.tf` : VPC custom, subnet, IP statique, firewall (22, 80, 443)
  - `vm.tf` : VM e2-medium Ubuntu 22.04 avec startup script (Docker, Caddy, Git)
  - `storage.tf` : Buckets bronze (offres JSON) + backups avec lifecycle policies
  - `bigquery.tf` : Datasets silver/gold avec tables offers, skills, formations, etc.
  - `iam.tf` : 3 Service Accounts (vm, terraform, deploy) + Workload Identity Federation
  - `outputs.tf` : Outputs utiles (IP, SSH command, secrets GitHub)

- **GitHub Actions CI/CD** (`.github/workflows/`) :
  - `terraform.yml` : Plan sur PR, Apply sur push main
  - `deploy.yml` : Build Docker + deploy sur VM via SSH

**Probl√®mes rencontr√©s:**

- **Variable `$PROJECT_ID` non d√©finie** :
  - Sympt√¥me : `gsutil mb` √©choue avec "Invalid bucket name"
  - Solution : Utiliser `$(gcloud config get-value project)` ou hardcoder `job-match-v0`

- **Billing account not linked** :
  - Sympt√¥me : `gcloud services enable` √©choue avec FAILED_PRECONDITION
  - Solution : Activer la facturation via Console GCP avant d'activer les APIs
  - Document√© dans GCP_IAM_GUIDE.md comme √©tape obligatoire

- **Terraform ne d√©ploie pas les changements de code** (cf. POSTMORTEM_miniterraform) :
  - Cause : Terraform compare la configuration, pas le contenu des images Docker
  - Solution : `docker compose build --no-cache --pull` + `down` + `up -d` dans deploy.yml

**D√©cisions techniques:**

- **Workload Identity Federation** (pas de cl√© JSON) : M√©thode recommand√©e par Google, pas de secret √† g√©rer
- **VM unique avec docker-compose** : Simple pour V0, migration vers Cloud Run possible en V1
- **Caddy sur VM** : SSL automatique avec Let's Encrypt, gratuit
- **IP statique** : Stabilit√© DNS, gratuit si attach√©e √† une VM
- **BigQuery pour Silver/Gold** : Analytics, pas de serveur √† g√©rer
- **Backend GCS pour Terraform** : State partag√© entre CI/CD et local

**Fichiers cr√©√©s:**
```
infra/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE_V0.md
‚îÇ   ‚îî‚îÄ‚îÄ GCP_IAM_GUIDE.md
‚îî‚îÄ‚îÄ terraform/
    ‚îú‚îÄ‚îÄ main.tf
    ‚îú‚îÄ‚îÄ variables.tf
    ‚îú‚îÄ‚îÄ network.tf
    ‚îú‚îÄ‚îÄ vm.tf
    ‚îú‚îÄ‚îÄ storage.tf
    ‚îú‚îÄ‚îÄ bigquery.tf
    ‚îú‚îÄ‚îÄ iam.tf
    ‚îú‚îÄ‚îÄ outputs.tf
    ‚îú‚îÄ‚îÄ terraform.tfvars.example
    ‚îî‚îÄ‚îÄ .gitignore
.github/workflows/
‚îú‚îÄ‚îÄ terraform.yml
‚îî‚îÄ‚îÄ deploy.yml
```

**Prochaines √©tapes:**
1. Cr√©er le bucket Terraform state : `gsutil mb -l EU gs://jobmatch-terraform-state-job-match-v0`
2. Configurer les secrets GitHub
3. Premier `terraform init` + `terraform apply`
4. Configurer DNS vers IP statique

---

### 2025-12-29 (30) - Local Ollama Docker + README + Debug cv-ingestion LLM

**Contexte:** Ajouter un serveur Ollama local en Docker avec mod√®les Mistral pr√©-t√©l√©charg√©s, cr√©er le README global du projet, et d√©bugger les probl√®mes de connexion LLM pour cv-ingestion.

**R√©alisations:**

- **Service local-ollama Docker** :
  - Nouveau dossier `app/local_ollama/` avec Dockerfile et entrypoint
  - Mod√®les `mistral:latest` et `mistral:7b` t√©l√©charg√©s au build
  - Service ajout√© dans docker-compose.yml (port 11434)
  - Volume `ollama_data` pour persister les mod√®les

- **README.md global** :
  - Architecture du projet avec arborescence
  - Table des services avec ports et status (OK/WIP)
  - Instructions de d√©marrage (docker-compose + dev.sh)
  - Documentation de tous les services : gui, ai-assistant, cv-ingestion, offre-ingestion, matching, local-ollama
  - Configuration et variables d'environnement
  - Stack technique et conventions

- **Documentation sch√©mas Django** :
  - Explication du mod√®le User (AbstractUser avec pr√©f√©rences)
  - Explication du mod√®le CandidateProfile
  - Relation CandidateProfile ‚Üî ExtractedLine via ProfileItemSelection (N:N)

**Probl√®mes rencontr√©s:**

- **cv-ingestion : "model 'ministral-3:14b' not found"** :
  - Sympt√¥me : Erreur 404 sur l'endpoint `/v1/chat/completions`
  - Cause : Le serveur distant `llm.molp.fr` expose l'API Ollama native (`/api/tags`, `/api/generate`) mais l'API OpenAI-compatible (`/v1/models`, `/v1/chat/completions`) ne liste aucun mod√®le
  - Le SDK OpenAI utilis√© par cv-ingestion appelle `/v1/chat/completions` qui retourne "model not found"
  - `/api/tags` montre les mod√®les mais `/v1/models` retourne une liste vide
  - Status : Non r√©solu - probl√®me c√¥t√© serveur `llm.molp.fr`

**D√©cisions techniques:**

- **Mod√®les t√©l√©charg√©s au build** : Plut√¥t qu'au runtime (entrypoint), pour un d√©marrage plus rapide des containers
- **Volume Docker pour Ollama** : Les mod√®les sont volumineux (~4GB), √©vite de re-t√©l√©charger √† chaque rebuild
- **README structur√© par service** : Chaque microservice a sa section avec exemples curl

**Fichiers cr√©√©s/modifi√©s:**
- `app/local_ollama/Dockerfile` : Image Ollama avec pull des mod√®les
- `app/local_ollama/entrypoint.sh` : Script de d√©marrage simplifi√©
- `docker-compose.yml` : Service local-ollama + volume ollama_data
- `README.md` : Documentation compl√®te du projet (nouveau fichier)

---

### 2025-12-24 (29) - Boutons Voir/T√©l√©charger DOCX pour CV et Lettre

**Contexte:** Am√©liorer l'UX de la page candidature en ajoutant des boutons d'action (voir/t√©l√©charger) pour les documents g√©n√©r√©s, avec export DOCX.

**R√©alisations:**

- **Nouveau layout document-item** :
  - Remplac√© les simples boutons texte par des cartes `.document-item` avec ic√¥nes d'action
  - Deux boutons par document : ≈ìil (voir) et fl√®che (t√©l√©charger DOCX)
  - Design coh√©rent avec hover effet violet

- **Export DOCX avec docx.js** :
  - Chargement dynamique de la librairie docx.js depuis unpkg CDN
  - Parsing intelligent du contenu : d√©tection des headers `--- TITLE ---`, bullet points, paragraphes
  - Formatage DOCX avec titres color√©s (#667eea), bullet points natifs
  - Nommage fichier avec nom entreprise slugifi√©

- **Am√©lioration modal preview** :
  - Ajout bouton "T√©l√©charger DOCX" dans le footer de la modal
  - Variable `currentPreviewType` pour savoir quel document est affich√©

**Fonctions JavaScript ajout√©es:**
- `downloadDocx(type)` : t√©l√©charge CV ou lettre selon le type
- `downloadCurrentDocx()` : t√©l√©charge le document actuellement pr√©visualis√©
- `generateDocx(content, title, fileName)` : g√©n√®re et t√©l√©charge le DOCX

**Fichiers modifi√©s:**
- `app/gui/templates/accounts/application_detail.html` : CSS + JS + HTML pour boutons action

---

### 2025-12-24 (28) - G√©n√©ration CV/Lettre de motivation + Fix async pattern

**Contexte:** Impl√©mentation de la g√©n√©ration IA de CV et lettres de motivation personnalis√©s pour les candidatures, avec correction du pattern async pour √©viter les timeouts.

**R√©alisations:**

- **G√©n√©ration de CV personnalis√©** :
  - Nouveau prompt `cv_generation.txt` avec optimisation ATS (intitul√© proche de l'offre, mots-cl√©s exacts)
  - Ajout des liens sociaux (LinkedIn, Portfolio, GitHub) dans le CV
  - Endpoint FastAPI `/generate/cv` avec task_id + polling

- **G√©n√©ration de lettre de motivation** :
  - Nouveau prompt `cover_letter_generation.txt`
  - Utilise le CV g√©n√©r√© comme r√©f√©rence pour coh√©rence
  - Endpoint FastAPI `/generate/cover-letter`

- **Sch√©mas Pydantic** (schemas.py) :
  - `CandidateContext` : profil complet avec social_links
  - `JobOfferContext` : offre cible
  - `GenerateCVRequest/Response`, `GenerateCoverLetterRequest/Response`
  - `GenerationTaskStatusResponse` pour le polling

- **UI g√©n√©ration** (application_detail.html) :
  - Boutons "G√©n√©rer CV" et "G√©n√©rer la lettre"
  - Animation loading pendant la g√©n√©ration
  - Polling status toutes les 2 secondes
  - Modal de preview pour visualiser les documents g√©n√©r√©s
  - Sauvegarde automatique en base apr√®s g√©n√©ration

- **Documentation pattern async** (docs/ASYNC_PATTERNS.md) :
  - Explication compl√®te du probl√®me de timeout
  - Diagramme du flow task_id + polling
  - Exemples code FastAPI, Django, JavaScript
  - Pi√®ges √† √©viter (BackgroundTasks vs create_task, to_thread)

**Probl√®mes rencontr√©s:**

- **"Service IA indisponible" (timeout 10s)** :
  - Sympt√¥me : Django timeout apr√®s 10s, mais ai-assistant g√©n√®re bien le CV (30s)
  - Cause : `BackgroundTasks.add_task()` n'est pas vraiment async - attend la fin de la fonction
  - Cause 2 : `provider.chat()` est synchrone, bloque l'event loop m√™me dans une fonction `async`

- **Solution double** :
  1. Remplacer `background_tasks.add_task(fn)` par `asyncio.create_task(fn())` pour retourner imm√©diatement
  2. Utiliser `asyncio.to_thread(provider.chat, ...)` pour ex√©cuter l'appel LLM synchrone dans un thread s√©par√©

- **docker-compose KeyError 'ContainerConfig'** :
  - Bug de docker-compose avec des containers stale
  - Solution : `docker-compose stop svc && docker-compose rm -f svc && docker-compose up -d svc`

**D√©cisions techniques:**

- **Task-based polling plut√¥t que streaming** : Pour g√©n√©ration one-shot (CV, lettre), le polling est plus simple et robuste que SSE
- **asyncio.create_task() plut√¥t que BackgroundTasks** : Seule fa√ßon d'avoir une vraie ex√©cution non-bloquante avec FastAPI
- **asyncio.to_thread() pour LLM calls** : Les SDKs OpenAI/Anthropic sont synchrones, n√©cessitent un thread pool
- **Documentation d√©di√©e** : Pattern async suffisamment complexe pour m√©riter un fichier docs/ASYNC_PATTERNS.md

**Fichiers cr√©√©s/modifi√©s:**
- `app/ai-assistant/src/main.py` : asyncio.create_task() pour g√©n√©ration
- `app/ai-assistant/src/llm/chat_handler.py` : asyncio.to_thread() pour LLM calls + social_links
- `app/ai-assistant/src/prompts/cv_generation.txt` : prompt CV avec ATS
- `app/ai-assistant/src/schemas.py` : CandidateContext.social_links
- `app/gui/accounts/views.py` : endpoints g√©n√©ration + status polling + save
- `app/gui/templates/accounts/application_detail.html` : UI g√©n√©ration compl√®te
- `docs/ASYNC_PATTERNS.md` : documentation pattern pending/done

---

### 2025-12-24 (27) - Candidatures sur Home + Fix ENV_MODE Docker + Migrations
**Contexte:** Afficher les candidatures r√©centes sur la page d'accueil et r√©soudre les probl√®mes de configuration Docker (ENV_MODE, base de donn√©es).

**R√©alisations:**

- **Affichage candidatures sur page d'accueil** :
  - Nouvelle vue `HomeView` dans `config/views.py` (remplace `TemplateView` g√©n√©rique)
  - Passe `recent_applications` (3 derni√®res) et `applications_count` au template
  - Mini-cartes dans la section "Suivi des candidatures" avec : entreprise, status color√©, titre
  - Badge compteur dans le header de la carte
  - Lien "Voir toutes mes candidatures (N)"

- **Styles CSS pour mini-cartes** :
  - `.application-mini-card` avec bordure gauche color√©e
  - Badges status color√©s : `.app-status-added` (gris), `.app-status-in_progress` (bleu), `.app-status-applied` (orange), `.app-status-interview` (violet), `.app-status-accepted` (vert), `.app-status-rejected` (rouge)

- **Fix ENV_MODE dans docker-compose.yml** :
  - Ajout `ENV_MODE=dev` pour le service gui
  - Ajout variables PostgreSQL : `POSTGRES_HOST=db`, `POSTGRES_PORT=5432`, etc.
  - Suppression d√©pendances vers services non impl√©ment√©s (cv-ingestion, ai-assistant)

- **Commande `full-restart` dans dev.sh** :
  - `./dev.sh full-restart [svc]` : stop + rm + build + up
  - Message d'aide am√©lior√© avec liste format√©e

- **Fix IntegrityError sur import d'offre** :
  - Remplac√© `Application.objects.create()` par `get_or_create()` dans `ImportOfferView`
  - √âvite erreur si l'Application existe d√©j√† pour ce user+offre

**Probl√®mes rencontr√©s:**
- **`no such table: accounts_application`** (SQLite erreur) :
  - Cause : `ENV_MODE` non d√©fini ‚Üí Django utilisait mode "local" mais psycopg2 absent ‚Üí fallback SQLite
  - Solution : ajouter `ENV_MODE=dev` dans docker-compose.yml pour forcer PostgreSQL

- **`relation "accounts_application" does not exist`** (PostgreSQL erreur) :
  - Cause : migration cr√©√©e dans le container mais pas persist√©e dans le code source
  - Solution : `docker cp` pour r√©cup√©rer la migration, puis `makemigrations && migrate`

- **Base de donn√©es vide apr√®s full-restart** :
  - Cause : nouveau container avec PostgreSQL vide (pas de user)
  - Solution : cr√©er superuser via `manage.py shell`

**D√©cisions techniques:**
- **Vue HomeView plut√¥t que TemplateView** : n√©cessaire pour passer le contexte dynamique (candidatures)
- **get_or_create pour Application** : idempotent, √©vite les erreurs de doublon
- **docker cp pour migrations** : r√©cup√©rer les fichiers g√©n√©r√©s dans le container vers le code source

**Fichiers cr√©√©s/modifi√©s:**
- `app/gui/config/views.py` : nouvelle HomeView
- `app/gui/config/urls.py` : utilise HomeView au lieu de TemplateView
- `app/gui/templates/home.html` : mini-cartes candidatures + CSS
- `docker-compose.yml` : ENV_MODE=dev + variables PostgreSQL
- `dev.sh` : commande full-restart + aide am√©lior√©e
- `app/gui/api/views.py` : get_or_create pour Application
- `app/gui/accounts/migrations/0016_add_application_model.py` : migration Application

---

### 2025-12-24 (26) - Dev Workflow + Base de donn√©es partag√©e + Script dev.sh
**Contexte:** R√©soudre le probl√®me de perte de donn√©es entre les rebuilds Docker et am√©liorer le workflow de d√©veloppement.

**R√©alisations:**

- **Base de donn√©es partag√©e Local/Docker** :
  - Avant : Local utilisait SQLite, Docker utilisait PostgreSQL ‚Üí donn√©es s√©par√©es
  - Apr√®s : Les deux modes utilisent le m√™me PostgreSQL Docker
  - Local se connecte via `localhost:5433` (port expos√©)
  - Docker se connecte via `db:5432` (r√©seau interne)
  - Modification dans `settings.py` : config DB unifi√©e

- **Script interactif `dev.sh`** :
  - Menu interactif avec emojis et couleurs
  - Affichage du status des containers au d√©marrage
  - Sous-menus : Start, Stop, Rebuild, Logs, Shell, Migrations, Reset DB
  - Mode rapide en ligne de commande : `./dev.sh start`, `./dev.sh rebuild gui`, etc.
  - Gestion gracieuse des services non impl√©ment√©s (skip avec warning)
  - Option "Start core services only" pour ne d√©marrer que db + gui

- **Commandes rapides disponibles** :
  ```bash
  ./dev.sh start              # D√©marre db + gui
  ./dev.sh stop               # Arr√™te tout (donn√©es pr√©serv√©es)
  ./dev.sh rebuild gui        # Rebuild + restart gui
  ./dev.sh logs gui           # Voir les logs
  ./dev.sh migrate            # Appliquer migrations
  ./dev.sh shell              # Django shell
  ```

**Probl√®mes rencontr√©s:**
- **Perte de donn√©es apr√®s rebuild** : caus√©e par l'utilisation de bases diff√©rentes (SQLite local vs PostgreSQL Docker)
  - Solution : unifier sur PostgreSQL, accessible via port expos√© en local
- **Migration manquante** : `no such table: accounts_application` apr√®s cr√©ation du mod√®le
  - Solution : `docker-compose exec -T gui python manage.py makemigrations && migrate`

**D√©cisions techniques:**
- **PostgreSQL partout** : coh√©rence des donn√©es entre modes de d√©veloppement
- **Volume Docker persistant** : `postgres_data` survit aux `docker-compose down` (sans `-v`)
- **Script interactif** : plus user-friendly que des commandes manuelles
- **Mode rapide CLI** : pour les actions fr√©quentes sans passer par le menu

**Fichiers cr√©√©s/modifi√©s:**
- `dev.sh` : script de d√©veloppement interactif
- `app/gui/config/settings.py` : config DB unifi√©e pour local/Docker

---

### 2025-12-24 (25) - Swagger Docs + Application Model + Candidatures UI
**Contexte:** Documenter l'API REST avec Swagger/OpenAPI, cr√©er le mod√®le Application (candidature) et afficher les candidatures en cards.

**R√©alisations:**

- **Documentation Swagger (drf-spectacular)** :
  - Ajout `drf-spectacular>=0.27` dans requirements.txt
  - Configuration dans settings.py : `SPECTACULAR_SETTINGS` avec titre, description, version
  - Routes ajout√©es : `/api/schema/` (JSON), `/api/docs/` (Swagger UI), `/api/redoc/` (ReDoc)
  - D√©corateurs `@extend_schema` sur toutes les vues API (tags, summary, request/response schemas)
  - Auth JWT int√©gr√©e avec `persistAuthorization: True` dans Swagger UI

- **Mod√®le Application (Candidature)** (migration 0016) :
  - Workflow status : added ‚Üí in_progress ‚Üí applied ‚Üí interview ‚Üí accepted/rejected
  - Liens : `imported_offer` (FK), `candidate_profile` (FK nullable)
  - Documents : `custom_cv` (TextField), `custom_cv_file` (FileField), `cover_letter`, `cover_letter_file`
  - M√©tadonn√©es : `interview_date`, `notes`, `history` (JSONField pour event tracking)
  - Helper methods : `add_history_event()`, `has_cv()`, `has_cover_letter()`, `get_completion_status()`
  - Dynamic upload paths : `applications/{user_id}/{app_id}/cv/` et `.../cover_letter/`

- **Auto-cr√©ation Application sur import** :
  - Dans `ImportOfferView.post()` (api/views.py) : cr√©ation automatique d'une Application apr√®s chaque ImportedOffer
  - Associe le `candidate_profile` si fourni lors de l'import

- **Page liste candidatures** (`/accounts/applications/`) :
  - Vue `applications_list_view` avec filtrage par status (query param `?status=`)
  - Compteurs par status : all, added, in_progress, applied, interview, accepted, rejected
  - Template cards avec : header (entreprise, titre), meta (lieu, contrat, remote), badge status, progress (CV, Lettre)
  - Grid responsive `grid-template-columns: repeat(auto-fill, minmax(320px, 1fr))`
  - Status badges color√©s (vert=accepted, bleu=applied, orange=in_progress, rouge=rejected)

- **Int√©gration home page** :
  - Lien "Suivi des candidatures" ‚Üí `/accounts/applications/`
  - Suppression du badge "coming soon"

**Probl√®mes rencontr√©s:**
- **Donn√©es perdues apr√®s rebuild** : l'offre test import√©e via l'extension a disparu apr√®s `docker-compose down/up`
  - Cause : volumes Docker recr√©√©s en dev
  - Note : comportement attendu, pas un bug

**D√©cisions techniques:**
- **drf-spectacular plut√¥t que drf-yasg** : plus moderne, meilleur support OpenAPI 3, maintenu activement
- **History en JSONField** : simplicit√©, pas besoin d'une table s√©par√©e pour le POC
- **Application auto-cr√©√©e** : chaque offre import√©e d√©marre automatiquement le workflow de candidature
- **Status workflow lin√©aire** : added ‚Üí in_progress ‚Üí applied ‚Üí interview ‚Üí {accepted, rejected}

**Fichiers cr√©√©s/modifi√©s:**
- `app/gui/requirements.txt` : ajout drf-spectacular
- `app/gui/config/settings.py` : config SPECTACULAR_SETTINGS
- `app/gui/api/urls.py` : routes schema/docs/redoc
- `app/gui/api/views.py` : extend_schema decorators + Application auto-create
- `app/gui/accounts/models.py` : Application model
- `app/gui/accounts/views.py` : applications_list_view
- `app/gui/accounts/urls.py` : route applications
- `app/gui/templates/accounts/applications_list.html` : nouveau template
- `app/gui/templates/home.html` : lien candidatures

---

### 2025-12-24 (24) - API REST Extension Navigateur (DRF + JWT)
**Contexte:** Cr√©er une API REST pour l'extension navigateur JobMatch qui capture des offres d'emploi depuis n'importe quel site web.

**R√©alisations:**

- **Nouvelle app Django `api/`** :
  - Structure compl√®te : `urls.py`, `views.py`, `serializers.py`, `apps.py`
  - S√©paration claire entre pages web (accounts) et API REST (api)
  - Pr√™t pour versioning futur (`/api/v1/`, `/api/v2/`)

- **Authentification JWT (SimpleJWT)** :
  - `POST /api/auth/token/` - Login ‚Üí access + refresh tokens
  - `POST /api/auth/token/refresh/` - Rafra√Æchir le token
  - `GET /api/auth/user/` - Infos utilisateur courant
  - `POST /api/auth/logout/` - Blacklist refresh token
  - Config : access 15min, refresh 7 jours, rotation automatique

- **Endpoints offres import√©es** :
  - `POST /api/offers/import/` - Importer une offre captur√©e
  - `GET /api/offers/` - Lister les offres de l'utilisateur
  - `GET/PATCH/DELETE /api/offers/<id>/` - D√©tail, mise √† jour status, suppression
  - `GET /api/health/` - Health check

- **Mod√®le `ImportedOffer`** (migration 0015) :
  - Champs source : `source_url`, `source_domain`, `captured_at`
  - Champs offre : `title`, `company`, `location`, `description`, `contract_type`, `remote_type`, `salary` (JSON), `skills` (JSON)
  - Matching : `match_score`, `matched_at` (TODO: int√©gration service matching)
  - Status : new, viewed, saved, applied, rejected
  - Contrainte unicit√© : `(user, source_url)` √©vite les doublons

- **Configuration CORS** :
  - Dev : `CORS_ALLOW_ALL_ORIGINS = True`
  - Prod : regex pour `chrome-extension://` et `moz-extension://`
  - Headers autoris√©s : authorization, content-type, etc.

- **D√©pendances ajout√©es** :
  - `djangorestframework>=3.14`
  - `djangorestframework-simplejwt>=5.3`
  - `django-cors-headers>=4.3`

**Probl√®mes rencontr√©s:**
- **ModuleNotFoundError rest_framework** : d√©pendances non install√©es en local
  - Solution : `pip install djangorestframework djangorestframework-simplejwt django-cors-headers`
- **Port 8085 d√©j√† utilis√©** : serveur Django d√©j√† lanc√©
  - Solution : `docker-compose down && build && up`

**D√©cisions techniques:**
- **App s√©par√©e `api/`** : meilleure s√©paration des responsabilit√©s que tout mettre dans `accounts`
- **JWT plut√¥t que sessions** : les sessions Django ne fonctionnent pas cross-origin pour les extensions
- **Rotation des refresh tokens** : s√©curit√© renforc√©e, ancien token blacklist√© apr√®s refresh
- **camelCase dans API** : convention frontend, snake_case dans les mod√®les Django
- **Contrainte unicit√© sur URL** : un utilisateur ne peut pas importer deux fois la m√™me offre

**TODOs document√©s:**
1. **Matching service integration** : appeler POST /match lors de l'import d'une offre
2. **CORS security** : restreindre aux IDs d'extensions sp√©cifiques en production

**Fichiers cr√©√©s:**
- `app/gui/api/__init__.py`, `apps.py`, `urls.py`, `views.py`, `serializers.py`
- `app/gui/accounts/migrations/0015_add_imported_offer.py`
- `docs/api_extension.md` - Documentation compl√®te de l'API

---

### 2025-12-24 (23) - Architecture Offres/Matching + Infrastructure Cloud + Strat√©gie ML
**Contexte:** Concevoir l'architecture d'int√©gration entre le GUI, le service offres (Mohamed) et le service matching (Maxime), avec une vision cloud et strat√©gie ML long terme.

**R√©alisations:**

- **Analyse base offers.db (Silver)** :
  - 13 tables SQLite : offers (principale), offers_lieu_travail, offers_entreprise, offers_salaire, offers_competences, etc.
  - 150 offres sample avec format France Travail (codes ROME, NAF)
  - Champs cl√©s identifi√©s pour l'UI : intitule, typeContratLibelle, libelle (salaire), competences, formations

- **Architecture offres document√©e** (`docs/interface_gui_offers.md`) :
  - Option 1 (recommand√©e) : API REST expos√©e par `offre-ingestion` ‚Üí GUI consomme
  - Option 2 (pragmatique court terme) : Base partag√©e avec mod√®le Django `managed=False`
  - Mapping champs UI ‚Üî tables SQLite

- **Architecture matching document√©e** (`docs/interface_gui_offers_match.md`) :
  - Flux complet : GUI ‚Üí cv_embedding ‚Üí Matcher ‚Üí (id, score) top 20 ‚Üí GUI ‚Üí offre-ingestion ‚Üí d√©tails
  - Mod√®le cache `MatchResult` avec TTL 24h et invalidation sur changement profil
  - Mod√®les Django : `JobOffer`, `JobOfferSkill`, `MatchResult`
  - API specs : POST /match (CV embedding ‚Üí scores), GET /offers/{id} (d√©tail offre)

- **Analyse critique architecture actuelle** :
  - Points forts : microservices Docker, shared/ package, Factory pattern LLM, Medallion (Bronze‚ÜíSilver‚ÜíGold)
  - Am√©liorations sugg√©r√©es : pgvector, message queue, monitoring/alerting, CI/CD complet

- **Recommandation infrastructure GCP** :
  - Services : Cloud Run (serverless), Cloud SQL + pgvector, Vertex AI (embeddings), BigQuery, Memorystore
  - Co√ªts estim√©s : MVP ~50-60$/mois, Growth ~300-400$/mois
  - Migration en 4 phases : Local ‚Üí GCP MVP ‚Üí GCP Growth ‚Üí GCP Scale

- **Strat√©gie ML & Embeddings** :
  - MVP : sentence-transformers pre-trained (all-MiniLM-L6-v2), pas de MLflow
  - V1 : collecte donn√©es via `OfferInteraction` model (vues, applications, embauches)
  - V2 : fine-tuning avec MLflow (contrastive learning, cross-encoder, learning to rank)
  - Dataset potentiel : profils + offres + candidatures = supervision implicite

- **Mod√®le OfferInteraction con√ßu** :
  ```python
  class OfferInteraction(models.Model):
      user = models.ForeignKey(User)
      offer_external_id = models.CharField(max_length=50)
      match_score = models.FloatField()  # Score initial du matcher
      viewed = models.BooleanField()
      time_spent_seconds = models.IntegerField()
      saved = models.BooleanField()
      applied = models.BooleanField()
      got_interview = models.BooleanField(null=True)
      got_hired = models.BooleanField(null=True)
  ```

**Probl√®mes rencontr√©s:**
- **Pandoc LaTeX unicode** : caract√®res ‚Üî, ‚úÖ non support√©s par pdflatex
  - Solution 1 : xelatex engine
  - Solution 2 : Python markdown + wkhtmltopdf (sans LaTeX)

**D√©cisions techniques:**
- **API REST (Option 1)** : d√©couplage propre GUI/offres, Mohamed contr√¥le son API
- **Cache lazy refresh** : TTL 24h avec invalidation explicite (pas de refresh proactif)
- **pgvector recommand√©** : PostgreSQL extension pour recherche vectorielle avec index HNSW
- **GCP plut√¥t qu'AWS** : meilleur rapport co√ªt/features pour ML (Vertex AI, BigQuery)
- **MLflow diff√©r√©** : overkill pour MVP avec mod√®les pre-trained, utile uniquement pour fine-tuning
- **Collecte donn√©es implicite** : tracker les interactions d√®s le MVP pour pr√©parer le fine-tuning futur

**Documents cr√©√©s:**
- `docs/interface_gui_offers.md` - Interface GUI ‚Üî Offres
- `docs/interface_gui_offers_match.md` - Architecture compl√®te avec matching, cache, cloud, ML
- `docs/interface_gui_offers_match.pdf` - Export PDF pour l'√©quipe

---

### 2025-12-24 (22) - UI Success Cards + Export DOCX + Ruff fixes
**Contexte:** Enrichir les cartes de succ√®s professionnels avec toggle, visualisation et export, et corriger les erreurs Ruff pour le pre-commit hook.

**R√©alisations:**

- **Cartes succ√®s enrichies** :
  - Toggle "Profil candidat" (comme exp√©riences, √©ducation) pour inclure/exclure du profil
  - Bouton "voir" (ic√¥ne ≈ìil) ‚Üí modal de visualisation avec d√©tails STAR
  - Bouton "supprimer" (ic√¥ne corbeille) ‚Üí modal de confirmation
  - Nouveau champ `is_active` sur `ProfessionalSuccess` (migration 0014)
  - Endpoint `success_update_view` mis √† jour pour g√©rer `is_active`

- **Modal de visualisation** :
  - Affichage complet : Titre, Situation, T√¢che, Actions, R√©sultats, Comp√©tences
  - Largeur 900px (50% plus large que le d√©faut 600px)
  - Bouton "Export DOCX" pour t√©l√©chargement Word

- **Export DOCX** :
  - Biblioth√®que `docx.js` v8.5.0 charg√©e dynamiquement depuis CDN (unpkg)
  - Build UMD (`index.umd.js`) pour compatibilit√© browser
  - G√©n√©ration document Word avec sections STAR format√©es (titres en couleur #667eea)
  - T√©l√©chargement automatique avec nom fichier bas√© sur le titre
  - Feedback visuel : "Chargement..." puis "T√©l√©charg√© !" avec gestion erreurs

- **R√®gle #6 g√©n√©ralis√©e** :
  - R√®gle "questions NON AMBIGU√ãS" appliqu√©e √† toutes les phases du coaching STAR
  - Exemples MAUVAIS/BON g√©n√©riques (pas seulement Phase 6)

- **Corrections Ruff pre-commit** :
  - `SIM105` : `contextlib.suppress()` au lieu de `try/except/pass` (2 occurrences dans views.py)
  - `F841` : variable `initial_message` inutilis√©e supprim√©e
  - `UP028` : `yield from` au lieu de `for/yield` o√π applicable (providers.py)
  - `noqa: UP028` ajout√© o√π `yield from` incompatible avec `try/except` fallback (chat_handler.py)

- **Corrections Bandit pre-commit** :
  - `B104` : `# noqa: S104` ne fonctionne pas pour Bandit ‚Üí utiliser `# nosec B104`
  - `B110` : `try/except/pass` supprim√© - le `.filter().first()` Django retourne `None` sans exception

**Probl√®mes rencontr√©s:**
- **Export DOCX sans action** :
  - Cause 1 : mauvais CDN (`jsdelivr` avec path incorrect)
  - Cause 2 : Build `index.min.js` au lieu de `index.umd.js` (non compatible browser)
  - Solution : utiliser `unpkg.com/docx@8.5.0/build/index.umd.js`
- **Ruff SIM105 faux positif** : `try/except/pass` flagg√© mais `contextlib.suppress` est plus idiomatique
- **Ruff UP028 incompatible avec try/except** : `yield from` ne permet pas de catch les exceptions du g√©n√©rateur
  - Solution : ajouter `# noqa: UP028` avec explication
- **Bandit B104 non ignor√©** : `# noqa: S104` (syntaxe Ruff/flake8) ne fonctionne pas pour Bandit
  - Solution : utiliser `# nosec B104` (syntaxe Bandit)
- **Bandit B110 try/except/pass** : code inutile car `.filter().first()` retourne `None` au lieu de lever une exception
  - Solution : supprimer le try/except

**D√©cisions techniques:**
- **CDN unpkg plut√¥t que jsdelivr** : URLs plus simples et pr√©visibles pour les libs npm
- **Build UMD** : n√©cessaire pour usage browser sans bundler (ESM ne fonctionne pas avec script tag)
- **Chargement dynamique** : √©vite d'inclure 500KB de lib si l'utilisateur n'exporte jamais
- **contextlib.suppress** : plus pythonique que `try/except/pass` pour ignorer une exception sp√©cifique
- **noqa avec explication** : documenter pourquoi la r√®gle est ignor√©e pour la maintenance future

---

### 2025-12-24 (21) - Refonte Prompt STAR + Auto-cr√©ation Succ√®s
**Contexte:** Le chatbot STAR √©tait trop verbeux (400+ mots par message) et ne permettait pas la cr√©ation automatique des succ√®s en fin de conversation.

**R√©alisations:**

- **Refonte compl√®te `star_coaching.txt`** :
  - Messages courts : 2-4 phrases max par r√©ponse (vs 400+ mots avant)
  - 6 phases strictes : Choix exp√©rience ‚Üí S ‚Üí T ‚Üí A ‚Üí R ‚Üí Cr√©ation
  - R√®gle "une seule phase √† la fois" : le LLM n'√©voque jamais la phase suivante
  - Exemples MAUVAIS/BON dans le prompt pour guider le mod√®le
  - Marqueur `[STAR_COMPLETE]` avec JSON structur√© √† la fin

- **D√©tection automatique `[STAR_COMPLETE]`** dans `profile.html` :
  - Nouvelle m√©thode `handleStarComplete(rawText, contentDiv)` dans `StarChatbot`
  - Extraction du JSON apr√®s le marqueur via regex
  - Appel API `/accounts/api/successes/create/` avec les donn√©es STAR
  - Message de confirmation "‚úÖ Succ√®s ajout√© √† ton profil !"
  - Fermeture automatique du chat apr√®s 2 secondes

- **Chat expandable am√©lior√©** :
  - CSS `position: fixed` avec overlay backdrop (modal-like)
  - Couvre tout l'√©cran y compris le titre de section
  - Centr√© avec `top/left: 50%` + `transform: translate(-50%, -50%)`
  - z-index 1000 pour le chat, 999 pour le backdrop

**Probl√®mes rencontr√©s:**
- **Expand ne couvrait pas le titre** : CSS `position: absolute` sur `.achievements-layout` ne remontait pas assez
  - Solution : passer √† `position: fixed` avec comportement modal

**D√©cisions techniques:**
- **Marqueur `[STAR_COMPLETE]` plut√¥t que extraction s√©par√©e** : le LLM g√©n√®re le JSON directement, pas besoin d'un second appel LLM
- **is_draft: false** envoy√© √† l'API : le succ√®s est complet quand auto-cr√©√© (toutes les infos STAR collect√©es)
- **Fermeture apr√®s 2s** : donne le temps √† l'utilisateur de lire la confirmation avant reset

**Patterns appliqu√©s:**
- **Marqueur de fin dans le stream** : `[MARKER]` + JSON permet d'extraire des donn√©es structur√©es du stream SSE
- **Prompt engineering strict** : exemples MAUVAIS/BON explicites pour contraindre le comportement du mod√®le
- **Phases s√©quentielles** : emp√™cher le LLM de "sauter" des √©tapes en interdisant de mentionner les phases suivantes

---

### 2025-12-24 (20) - Markdown + Chat Expandable
**Contexte:** Am√©liorer l'affichage des r√©ponses du chatbot (rendu markdown) et permettre d'agrandir la fen√™tre de chat pour couvrir la sidebar pendant une conversation.

**R√©alisations:**

- **Rendu Markdown dans le chat** :
  - Ajout de `marked.js` (v11.1.1) via CDN pour parser le markdown des r√©ponses LLM
  - Nouvelle m√©thode `renderMarkdown(text)` dans StarChatbot et PitchChatbot
  - Modification de `addMessage()` : markdown pour assistant, `escapeHtml()` pour user
  - Modification de `appendToStreamingMessage()` : utilise `textContent` pendant le streaming
  - Modification de `finishStreamingMessage()` : applique `marked.parse()` √† la fin du stream
  - CSS ajout√© pour les √©l√©ments markdown (p, strong, em, ul, ol, li, blockquote, code, pre, h1-h3)

- **Chat extensible (expand/collapse)** :
  - CSS `.achievements-layout.chat-expanded` : position absolute pour couvrir la sidebar
  - Bouton expand dans les headers des deux chats (STAR et Pitch) avec ic√¥nes SVG
  - M√©thodes `expandChat()`, `collapseChat()`, `toggleExpand()` dans les deux classes
  - Auto-expand dans `startConversation()` : le chat s'agrandit automatiquement
  - Auto-collapse dans `resetChat()` : le chat se r√©duit quand on clique "Nouvelle conversation"
  - Toggle manuel via bouton dans le header

**D√©cisions techniques:**
- **marked.js** : biblioth√®que standard l√©g√®re (CDN) plut√¥t que solution custom
- **textContent pendant streaming** : √©vite les probl√®mes d'injection HTML pendant l'accumulation des tokens, markdown appliqu√© une seule fois √† la fin
- **CSS position absolute** : permet de superposer le chat sur la sidebar sans modifier le layout de base

**Patterns appliqu√©s:**
- Streaming + markdown : accumuler en texte brut, parser √† la fin pour √©viter les √©tats interm√©diaires cass√©s
- UI responsive : un bouton toggle avec deux ic√¥nes (expand/collapse) selon l'√©tat CSS

---

### 2025-12-24 (19) - SSE Streaming pour Chat IA + Fix 404 polling
**Contexte:** Impl√©menter le streaming SSE (Server-Sent Events) pour afficher les r√©ponses du chatbot token par token, et corriger un bug 404 sur le polling du status.

**R√©alisations:**

- **Fix 404 sur chat status polling** :
  - Bug : `/accounts/api/chat/status/{task_id}/` retournait 404
  - Cause : `chat_start_view` recevait le `task_id` de ai-assistant mais ne cr√©ait pas de `ChatMessage` avec ce task_id
  - Solution : ajout de `ChatMessage.objects.create(conversation=conversation, role="assistant", content="", status="pending", task_id=task_id)` apr√®s r√©ception du task_id

- **Configuration LLM_MAX_TOKENS** :
  - Ajout dans `app/ai-assistant/.env` : `LLM_MAX_TOKENS=4096`
  - Valeur r√©cup√©r√©e par `config.py` avec fallback √† 4096

- **Streaming SSE complet** (architecture 3 couches) :
  1. **LLM Providers** (`providers.py`) :
     - Nouvelle m√©thode abstraite `chat_stream()` sur `LLMProvider`
     - Impl√©mentation pour OpenAI : `stream=True` + iteration sur `chunk.choices[0].delta.content`
     - Impl√©mentation pour Anthropic : `messages.stream()` context manager + `stream.text_stream`
     - Impl√©mentation pour Ollama : m√™me pattern qu'OpenAI (API compatible)

  2. **FastAPI Endpoints** (`main.py`) :
     - Nouvelle fonction `_sse_generator()` : formate les tokens en SSE (`data: {"token": "..."}`)
     - Endpoint `/chat/start/stream` : d√©marre une conversation avec r√©ponse streaming
     - Endpoint `/chat/message/stream` : envoie un message avec r√©ponse streaming
     - Headers SSE : `Cache-Control: no-cache`, `X-Accel-Buffering: no` (nginx)

  3. **Django Proxy** (`views.py`) :
     - `chat_start_stream_view` : cr√©e ChatConversation + ChatMessage, proxy le stream SSE
     - `chat_message_stream_view` : cr√©e ChatMessage user + assistant, proxy le stream
     - Accumulation du contenu pendant le stream pour sauvegarder la r√©ponse compl√®te
     - `StreamingHttpResponse` avec `content_type="text/event-stream"`

- **Frontend JavaScript** (`profile.html`) :
  - Propri√©t√©s ajout√©es aux chatbots : `useStreaming = true`, `currentStreamingMessage`
  - `startConversationStreaming()` : utilise `fetch()` + `response.body.getReader()` pour lire le stream
  - `sendMessageStreaming()` : m√™me pattern pour les messages suivants
  - `createStreamingMessage()` : cr√©e une bulle vide avec classe `.streaming`
  - `appendToStreamingMessage()` : ajoute le token √† la bulle courante
  - `finishStreamingMessage()` : retire la classe `.streaming` et finalise
  - Pattern `ReadableStream` avec `TextDecoder` pour parser les chunks SSE
  - Fallback automatique si `useStreaming = false`

**Probl√®mes rencontr√©s:**
- **404 sur /api/chat/status/{task_id}/** :
  - Cause : ChatMessage avec task_id manquant dans la base
  - Diagnostic : les logs montraient que le LLM r√©pondait correctement mais la GUI ne recevait rien
  - Solution : cr√©er le ChatMessage "pending" imm√©diatement apr√®s avoir re√ßu le task_id

**D√©cisions techniques:**
- **Option 1 choisie : Proxy Django** plut√¥t que WebSocket direct ou connexion directe client‚Üíai-assistant
  - Avantages : architecture coh√©rente, auth centralis√©e, CORS simplifi√©
  - Inconv√©nient : latence l√©g√®rement sup√©rieure (hop suppl√©mentaire)
  - Impact scaling : le serveur Django doit maintenir les connexions ouvertes pendant le streaming

**Impact Scaling** :
- **Django** : chaque requ√™te streaming bloque un worker pendant toute la dur√©e de g√©n√©ration (10-60s selon le LLM)
  - Mitigation : utiliser Gunicorn avec workers async (gevent/eventlet) ou passer √† ASGI (Daphne/Uvicorn)
  - Alternative : augmenter le nombre de workers proportionnellement aux users concurrents
- **ai-assistant FastAPI** : d√©j√† async natif, scale bien avec uvicorn
- **LLM** : le bottleneck principal reste le temps de g√©n√©ration du LLM
- **Recommandation prod** : si >100 users concurrents, envisager une connexion WebSocket directe client‚Üíai-assistant avec auth par token JWT

---

### 2025-12-24 (18) - Prompts proactifs + Transmission LLM Config + Logs debug
**Contexte:** Am√©liorer les prompts des assistants IA pour qu'ils soient proactifs (proposent au lieu de poser des questions), transmettre la config LLM utilisateur aux assistants, et ajouter des logs de debug pour les appels LLM.

**R√©alisations:**

- **Prompts proactifs** (`star_coaching.txt`, `pitch_coaching.txt`) :
  - Ajout R√®gle 0 : "Pr√©sente-toi et explique le processus" d√®s le premier message
  - STAR : se pr√©sente comme coach STAR, explique les √©tapes (choix exp√©rience ‚Üí S‚ÜíT‚ÜíA‚ÜíR ‚Üí validation)
  - Pitch : se pr√©sente comme coach pitch, annonce la g√©n√©ration directe des pitchs
  - Remplacement de `{existing_successes}` par `{professional_successes}` dans le prompt STAR

- **Transmission LLM Config utilisateur** :
  - Nouveau schema `LLMConfigRequest` avec `llm_endpoint`, `llm_model`, `llm_api_key`
  - Ajout `llm_config` optionnel dans `ChatStartRequest` et `ChatMessageRequest`
  - Helper `_build_llm_config()` dans main.py pour convertir en `LLMConfig`
  - Helper `_get_user_llm_config()` dans views.py pour r√©cup√©rer la config Premium+
  - Transmission de la config aux endpoints `/chat/start` et `/chat/message/async`
  - Les utilisateurs Premium+ peuvent utiliser leur propre LLM dans le chat

- **Logs debug LLM** (`providers.py`) :
  - Chaque provider (OpenAI, Anthropic, Ollama) loggue maintenant :
    - `=== LLM CALL (Provider) ===`
    - Endpoint utilis√©
    - Mod√®le utilis√©
    - System prompt (500 premiers chars)
    - Messages utilisateur (300 premiers chars chacun)
  - Permet de diagnostiquer les probl√®mes de connexion/configuration

- **Unification des donn√©es envoy√©es aux assistants** :
  - `build_system_prompt()` passe maintenant les m√™mes champs aux deux types de coaching
  - `professional_successes` (d√©taill√©) envoy√© aux deux pour √©viter les doublons

**Probl√®mes rencontr√©s:**
- **KeyError 'existing_successes'** : le prompt STAR r√©f√©ren√ßait `{existing_successes}` mais le code ne passait que `{professional_successes}`
  - Solution : remplacer les r√©f√©rences dans le prompt par des textes statiques ("ci-dessus", "d√©j√† formalis√©s")
- **GPU non triggered** : les logs n'apparaissaient pas car aucun appel LLM ne se faisait (erreur silencieuse)
  - Solution : ajout des logs explicites dans chaque provider avant l'appel LLM

**D√©cisions techniques:**
- **LLM config optionnel** : si non fourni ou endpoint vide, utilise les env vars du service
- **Logs avant l'appel** : permet de voir ce qui est envoy√© m√™me si l'appel √©choue
- **500/300 chars max** : √©vite de polluer les logs avec des prompts complets

---

### 2025-12-24 (17) - Interface Chat Pitch + Mod√®le Pitch Django
**Contexte:** Cr√©er l'interface utilisateur pour le coaching pitch et le mod√®le Django pour stocker les pitchs g√©n√©r√©s.

**R√©alisations:**

- **Mod√®le Pitch Django** (`accounts/models.py`) :
  - Champs : `title`, `pitch_30s`, `pitch_3min`, `key_strengths` (JSONField), `target_context`
  - M√©tadonn√©es : `source_conversation`, `is_draft`, `is_default`, `created_at`, `updated_at`
  - M√©thodes : `is_complete()`, `get_word_count_30s()`, `get_word_count_3min()`, `get_completion_percentage()`
  - Un seul pitch par d√©faut par utilisateur (save() override)

- **Migration 0012_add_pitch_model** : cr√©ation de la table Pitch

- **5 nouvelles vues API Pitch** (`views.py`) :
  - `pitch_list_view` - GET `/api/pitches/`
  - `pitch_create_view` - POST `/api/pitches/create/`
  - `pitch_detail_view` - GET `/api/pitches/<id>/`
  - `pitch_update_view` - POST `/api/pitches/<id>/update/`
  - `pitch_delete_view` - DELETE `/api/pitches/<id>/delete/`

- **Interface Chat Pitch** (`profile.html`) :
  - Section "Mon pitch" transform√©e : placeholder ‚Üí chat IA complet
  - Classe JavaScript `PitchChatbot` (~350 lignes) bas√©e sur `StarChatbot`
  - Envoi `coaching_type: 'pitch'` au d√©marrage de conversation
  - Couleur violet (#8b5cf6) pour diff√©rencier du coaching STAR (bleu)
  - Sidebar "Mes pitchs" avec compteur de mots 30s/3min
  - Lazy init avec MutationObserver quand la section devient visible

- **CSS sp√©cifique pitch** :
  - `.chat-welcome-note` : note italique pour le contexte
  - `.pitch-list strong` : couleur violette pour les libell√©s
  - `.pitch-card-info` : affichage compteurs de mots
  - `.pitches-sidebar .successes-count` : badge violet

**Probl√®mes rencontr√©s:**
- **docker-compose KeyError 'ContainerConfig'** : erreur r√©currente au rebuild
  - Solution : `docker-compose rm -sf <service> && docker-compose up -d <service>`
- **Migrations non d√©tect√©es dans container** : fichiers locaux non visibles
  - Solution : rebuild complet du container GUI apr√®s ajout des migrations

**D√©cisions techniques:**
- **R√©utilisation pattern StarChatbot** : m√™me architecture JS, seul `coaching_type` change
- **Couleur diff√©rente (violet)** : distinction visuelle claire entre STAR (bleu) et Pitch (violet)
- **Word count display** : aide l'utilisateur √† respecter les dur√©es cibles (75-80 mots pour 30s, 400-450 mots pour 3min)
- **Lazy initialization** : les chatbots ne sont instanci√©s que quand leur section est visible (performance)

---

### 2025-12-24 (16) - Extension ai-assistant pour Pitch Coaching
**Contexte:** √âtendre le module ai-assistant pour supporter √©galement le coaching de cr√©ation de pitch (30s et 3min), en r√©utilisant l'infrastructure existante du STAR coaching.

**R√©alisations:**

- **Extension schemas.py** :
  - Ajout de `CoachingType` enum (STAR, PITCH)
  - Ajout du champ `coaching_type` dans `ChatStartRequest` et `ChatMessageRequest`
  - Nouveaux champs dans `UserContext` : `skills`, `education`
  - Nouveaux sch√©mas `ExtractPitchRequest` et `ExtractPitchResponse`

- **Nouveau prompt pitch_coaching.txt** :
  - Structure pitch 30s : accroche, qui je suis, valeur ajout√©e, objectif
  - Structure pitch 3min : accroche, parcours, r√©alisations STAR, comp√©tences, vision, conclusion
  - Int√®gre les succ√®s STAR du candidat comme base pour les exemples concrets
  - Placeholders : {education}, {skills}, {professional_successes} (donn√©es STAR compl√®tes)

- **Mise √† jour chat_handler.py** :
  - `load_system_prompt(coaching_type)` : charge le prompt appropri√©
  - `format_education()`, `format_skills()` : nouvelles fonctions de formatage
  - `format_existing_successes(detailed=True)` : inclut donn√©es STAR compl√®tes pour pitch
  - `extract_pitch_data()` : extraction des pitchs 30s/3min depuis la conversation

- **Mise √† jour main.py** :
  - Endpoints `/chat/start` et `/chat/message/async` acceptent `coaching_type`
  - Nouvel endpoint `/chat/extract-pitch`

- **C√¥t√© Django** :
  - Ajout de `COACHING_TYPE_CHOICES` dans models.py
  - Nouveau champ `coaching_type` sur `ChatConversation`
  - Migration `0011_add_coaching_type_to_conversation`
  - `_build_user_context(coaching_type)` : pour pitch, inclut education, skills, et donn√©es STAR compl√®tes des succ√®s
  - Vues mises √† jour pour passer et utiliser le coaching_type

**Probl√®mes rencontr√©s:**
- **Aucun probl√®me majeur** : l'architecture g√©n√©rique du module a permis une extension facile

**D√©cisions techniques:**
- **Enum CoachingType** : permet d'ajouter facilement d'autres types de coaching √† l'avenir
- **Donn√©es STAR compl√®tes pour pitch** : le LLM peut citer les r√©sultats chiffr√©s des succ√®s dans le pitch
- **R√©utilisation des endpoints** : m√™me API, juste un param√®tre `coaching_type` diff√©rent
- **Priorit√© aux succ√®s finalis√©s** : pour le pitch, on prend d'abord les succ√®s non-draft

---

### 2025-12-24 (15) - AI Assistant STAR Coaching Chatbot
**Contexte:** Impl√©menter un chatbot IA pour accompagner les candidats dans la formalisation de leurs succ√®s professionnels avec la m√©thode STAR (Situation, Task, Action, Result)

**R√©alisations:**

- **Nouveau microservice ai-assistant (FastAPI)** :
  - Structure compl√®te : `app/ai-assistant/src/{main.py, config.py, schemas.py, task_store.py, llm/, prompts/}`
  - Endpoints : `/health`, `/chat/start`, `/chat/message/async`, `/chat/message/status/{task_id}`, `/chat/extract-success`
  - Pattern async polling identique √† cv-ingestion (task_id + status polling)
  - Support multi-LLM : OpenAI, Anthropic, Ollama via Factory Pattern
  - Dockerfile Python 3.12-slim, port 8084

- **LLM Chat Handler pour coaching STAR** :
  - `build_system_prompt()` : injecte le contexte utilisateur dans le prompt
  - `get_initial_message()` : message d'accueil personnalis√©
  - `process_chat_message()` : traitement des messages avec historique
  - `extract_star_data()` : extraction structur√©e des composants STAR

- **Prompt STAR coaching** (`prompts/star_coaching.txt`) :
  - Consultant expert en m√©thode STAR
  - Guide progressif S ‚Üí T ‚Üí A ‚Üí R
  - Encourage quantification et utilisation du "je" (pas "nous")
  - Placeholders pour contexte : {first_name}, {experiences}, {interests}, {existing_successes}

- **3 nouveaux mod√®les Django** :
  - `ChatConversation` : user, title, status (active/completed/abandoned), context_snapshot
  - `ChatMessage` : conversation, role (user/assistant/system), content, status, task_id, extracted_data
  - `ProfessionalSuccess` : user, title, situation, task, action, result, skills_demonstrated, is_draft
  - Migration `0010_add_chat_and_professional_success`

- **9 nouvelles vues Django** :
  - Chat : `chat_start_view`, `chat_message_view`, `chat_status_view`, `chat_history_view`
  - Succ√®s : `success_list_view`, `success_create_view`, `success_update_view`, `success_delete_view`
  - Helper `_build_user_context()` pour r√©cup√©rer les donn√©es utilisateur

- **Interface Chat UI** :
  - Layout deux colonnes : chat √† gauche, liste des succ√®s √† droite
  - Classe JavaScript `StarChatbot` (~400 lignes)
  - Polling status toutes les 2s avec typing indicator
  - Messages avec bulles stylis√©es (user bleu, assistant gris)
  - Lazy initialization avec MutationObserver

- **Int√©gration Docker** :
  - Service `ai-assistant` ajout√© √† docker-compose.yml
  - Variable `AI_ASSISTANT_URL` dans settings.py GUI
  - R√©seaux partag√©s jobmatch-network

**Probl√®mes rencontr√©s:**
- **docker-compose exec -T** : flag n√©cessaire pour commandes non-interactives (migrations)
- **Contexte compact√©** : session continu√©e apr√®s compactage, contexte r√©cup√©r√© du summary

**D√©cisions techniques:**
- **Chat int√©gr√©** (pas modal) : meilleure UX pour conversations longues
- **Microservice d√©di√©** : s√©paration des responsabilit√©s, scalabilit√© ind√©pendante
- **Persistance conversations** : historique en base pour reprendre les √©changes
- **Mod√®le ProfessionalSuccess d√©di√©** : pas d'utilisation d'ExtractedLine pour √©viter confusion
- **Context injection** : le LLM re√ßoit automatiquement profil, exp√©riences, int√©r√™ts, succ√®s existants

---

### 2025-12-23 (14) - Fix extraction personal_info/social_link + CSS/Text tweaks
**Contexte:** Bug o√π les donn√©es personnelles et liens sociaux extraits du CV n'√©taient pas sauvegard√©s correctement

**R√©alisations:**
- **Fix analyzer.py pour personal_info et social_link** :
  - Bug identifi√© : `parse_llm_response()` n'extrayait les champs structur√©s que pour `experience` et `education`
  - Les types `personal_info` et `social_link` avaient leurs ExtractedLine cr√©√©es mais avec tous les champs structur√©s √† `None`
  - Ajout des elif blocks pour extraire : first_name, last_name, email, phone, location (personal_info) et link_type, url (social_link)

- **Fix CSS checkboxes type de contrat** :
  - Les checkboxes s'affichaient verticalement au lieu d'horizontalement
  - Le CSS sur `.contract-checkboxes ul` ne fonctionnait pas car Django `CheckboxSelectMultiple` g√©n√®re un `<ul>` avec styles inline
  - Solution : rendu manuel des checkboxes avec `{% for choice in form.contract_types %}` au lieu de `{{ form.contract_types }}`
  - Nouveau CSS ciblant `.contract-checkbox-label` directement

- **Mise √† jour textes sections profil** :
  - "Mon pitch" subtitle : "Preparez votre presentation..." ‚Üí "Boostez votre presentation avec notre IA"
  - "Succes professionnels" subtitle : "Listez vos accomplissements..." ‚Üí "Laissez-vous guider par notre consultant IA pour formaliser vos succes"

**Probl√®mes rencontr√©s:**
- **ExtractedLine structured fields all None** :
  - Diagnostic via Django shell : `ExtractedLine.objects.filter(content_type="personal_info")` retournait des objets avec first_name=None
  - Cause : le code dans parse_llm_response() avait des elif pour experience/education mais pas pour les autres types structur√©s
  - Solution : ajout des branches elif pour personal_info et social_link

**D√©cisions techniques:**
- **Extraction conditionnelle par content_type** : chaque type avec des champs structur√©s a sa propre branche de parsing
- **Validation None-safe** : `item.get("field", "").strip() if item.get("field") else None` pour √©viter les strings vides

---

### 2025-12-23 (13) - Photo Upload avec Cropper.js + django-extensions local
**Contexte:** Ajouter l'upload de photo de profil avec recadrage style LinkedIn et outils de visualisation des mod√®les Django

**R√©alisations:**
- **django-extensions pour visualisation mod√®les** (local uniquement) :
  - `requirements-dev.txt` cr√©√© pour d√©pendances locales seulement
  - `django_extensions` ajout√© conditionnellement dans settings.py (`if ENV_MODE == "local"`)
  - Import try/except pour √©viter crash si non install√©
  - `graph_models accounts -o models.png` pour g√©n√©rer diagramme des relations

- **Photo de profil avec Cropper.js** :
  - Field `photo` (ImageField) ajout√© au mod√®le User
  - Migration 0007_add_photo_to_user cr√©√©e et appliqu√©e
  - Pillow ajout√© √† requirements.txt pour traitement images
  - `photo_upload_view` et `photo_delete_view` cr√©√©es
  - Routes `/photo/upload/` et `/photo/delete/` configur√©es
  - Media files servis en d√©veloppement (config/urls.py avec `static(MEDIA_URL)`)

- **Interface recadrage style LinkedIn** :
  - Cropper.js int√©gr√© via CDN (CSS + JS)
  - Modal en deux √©tapes : 1) S√©lection photo, 2) Recadrage
  - Vue circulaire pour le crop (style LinkedIn)
  - Zoom avec molette, drag pour repositionner
  - Sortie 400x400px JPEG qualit√© 90%
  - Boutons Annuler/Appliquer pour le crop

- **Configuration Docker** :
  - django_extensions conditionnel : charg√© uniquement si `ENV_MODE == "local"` ET module disponible
  - √âvite `ModuleNotFoundError` en Docker o√π le module n'est pas install√©

**Probl√®mes rencontr√©s:**
- **graphviz not found** : pydotplus n√©cessite le package syst√®me graphviz
  - Solution : `sudo apt install graphviz` (manuel car besoin de sudo)
- **ModuleNotFoundError: django_extensions** en Docker
  - Cause : django_extensions install√© en local mais pas dans requirements.txt Docker
  - Solution : ajout conditionnel avec try/except + v√©rification ENV_MODE == "local"
- **offre-ingestion sans Dockerfile** : `docker-compose build` √©choue
  - Solution : builder explicitement `docker-compose build gui cv-ingestion`

**D√©cisions techniques:**
- **Cropper.js** : biblioth√®que la plus populaire et mature pour le recadrage d'images
- **Two-step modal** : s√©pare la s√©lection du recadrage pour une UX plus claire
- **Crop circulaire** : correspond au style moderne des profils (LinkedIn, etc.)
- **Canvas toBlob** : conversion c√¥t√© client avant upload pour r√©duire la bande passante
- **requirements-dev.txt** : s√©pare les d√©pendances dev (graph_models) des d√©pendances prod
- **ENV_MODE check** : double protection (env var + try/except) pour √©viter crashes

---

### 2025-12-23 (12) - LLM Config Fallback + S√©lecteur d'abonnement + Modal Pricing
**Contexte:** Am√©liorer la gestion de la config LLM et ajouter un s√©lecteur d'abonnement avec comparaison des plans

**R√©alisations:**
- **LLM Config Fallback environnement** :
  - Si l'utilisateur n'a pas configur√© son LLM, le syst√®me utilise les variables d'environnement
  - Classe `LLMConfig` dans `analyzer.py` pour passer une config optionnelle
  - `get_llm_provider(config: LLMConfig | None)` : utilise config custom si fournie, sinon env vars
  - `analyze_cv_text()` et `analyze_cv_images()` acceptent un param√®tre `llm_config` optionnel
  - Endpoint `/extract/async` accepte des Form fields : `llm_endpoint`, `llm_model`, `llm_api_key`

- **Transmission config LLM GUI ‚Üí cv-ingestion** :
  - `cv_upload_view` envoie la config LLM de l'utilisateur si activ√©e ET si abonnement Premium+
  - V√©rification `user.subscription_tier not in ("free", "basic")` avant envoi
  - Donn√©es transmises via multipart form data

- **S√©lecteur d'abonnement** dans Account Settings :
  - 5 plans : Free (0‚Ç¨), Basic (9‚Ç¨), Premium (29‚Ç¨), Head Hunter (49‚Ç¨), Enterprise (99‚Ç¨)
  - Radio buttons stylis√©s avec prix et descriptions
  - Handler `form_type == "subscription"` pour mise √† jour du tier

- **Modal Pricing "Voir les offres"** :
  - Bouton gradient "Voir les offres" sur la carte abonnement
  - Modal plein √©cran avec comparaison des 5 plans
  - Tableau des fonctionnalit√©s : CVs, Offres, Analyses LLM, Support, etc.
  - Checkmarks verts / croix rouges pour chaque fonctionnalit√©
  - Prix affich√©s pour chaque plan

- **Restriction LLM Config par abonnement** :
  - Section LLM Config visible uniquement pour Premium, Head Hunter, Enterprise
  - Message explicatif pour Free/Basic : "disponible √† partir du plan Premium"
  - Section gris√©e (opacity: 0.6) pour plans non √©ligibles

**Probl√®mes rencontr√©s:**
- **File not read error** : tentative d'√©dition sans lecture pr√©alable
  - Solution : toujours lire le fichier avant de l'√©diter

**D√©cisions techniques:**
- **Form fields plut√¥t que JSON body** : compatible avec multipart/form-data pour upload fichier
- **Config optionnelle avec fallback** : pattern robuste, pas de breaking change
- **Restriction par tier** : v√©rification c√¥t√© serveur ET c√¥t√© template
- **Modal CSS natif** : pas de d√©pendance JS externe, animation simple

---

### 2025-12-23 (11) - Page Gestion Compte + LLM Config + Export RGPD
**Contexte:** Remplacer "Supprimer mon compte" par une page compl√®te de gestion du compte utilisateur

**R√©alisations:**
- **Page Account Settings** (`/accounts/settings/`) :
  - Sections : Identit√©, Email, Mot de passe, Abonnement, Config LLM, Export donn√©es, Suppression compte
  - Multi-formulaires sur une page (pattern `form_type` hidden field)
  - Messages de succ√®s/erreur par section
  - Danger zone en rouge pour suppression compte

- **Mod√®les ajout√©s** :
  - `SUBSCRIPTION_TIER_CHOICES` : Free, Basic, Premium, Head Hunter, Enterprise
  - `subscription_tier` field sur User (default="free")
  - `UserLLMConfig` model (OneToOne avec User) :
    - `is_enabled`, `llm_endpoint`, `llm_model`, `llm_api_key`
    - Permet aux utilisateurs d'utiliser leur propre LLM

- **Formulaires cr√©√©s** :
  - `AccountIdentityForm` : pr√©nom, nom
  - `AccountEmailForm` : changement email avec v√©rification unicit√©
  - `AccountPasswordForm` : mot de passe actuel + nouveau + confirmation
  - `UserLLMConfigForm` : activation + endpoint + mod√®le + API key

- **Export RGPD** (`/accounts/export/`) :
  - Endpoint `export_data_view`
  - Export JSON complet : profil, CVs, lignes extraites, lettres motivation, config LLM
  - Cl√© API exclue de l'export pour s√©curit√©
  - T√©l√©chargement fichier `jobmatch_data_{user_id}.json`

- **UI/UX** :
  - Sidebar profil : "Supprimer mon compte" ‚Üí "G√©rer mon compte" avec ic√¥ne engrenage
  - Template `settings.html` avec design coh√©rent (cards, gradients)
  - Formulaires stylis√©s Bootstrap 5

- **Migration 0004** : `add_subscription_and_llm_config`

**Probl√®mes rencontr√©s:**
- **File not read error** : outil Edit √©choue si fichier non lu pr√©alablement
  - Solution : toujours lire le fichier avant de l'√©diter
- **docker-compose KeyError 'ContainerConfig'** (r√©current)
  - Solution : `docker-compose down` complet avant `up`

**D√©cisions techniques:**
- **Multi-form pattern** : un seul template, plusieurs formulaires ind√©pendants via `form_type`
- **Re-login apr√®s password change** : `login(request, user)` apr√®s `form.save()` pour √©viter d√©connexion
- **get_or_create pour LLM config** : cr√©e automatiquement la config si inexistante
- **OneToOneField avec related_name** : `user.llm_config` pour acc√®s direct
- **API key non export√©e** : s√©curit√© RGPD (donn√©es sensibles exclues)

---

### 2025-12-23 (10) - Vision LLM + Prompts externalis√©s + Toggle/Edit UI
**Contexte:** Am√©liorer cv-ingestion pour supporter les PDF image (scann√©s) via Vision LLM, externaliser les prompts, et ajouter des contr√¥les UI sur les lignes extraites

**R√©alisations:**
- **Support Vision LLM** dans cv-ingestion :
  - M√©thode `supports_vision()` sur `LLMProvider` base class
  - M√©thode `analyze_images()` pour traiter les images avec Vision LLM
  - Support OpenAI (GPT-4V, GPT-4o), Anthropic (Claude 3/4), Ollama (LLaVA)
  - Nouvelle fonction `analyze_cv_images()` export√©e

- **Extraction PDF intelligente** :
  - `is_text_based_pdf()` : d√©tection auto texte vs image (heuristique: min 100 chars total, 50 chars/page)
  - `extract_pdf_content()` : retourne `PDFContent(is_text_based, text, images)`
  - `convert_pdf_to_images()` : PDF ‚Üí PNG via pdf2image/poppler
  - `ocr_images()` : fallback OCR via Tesseract si Vision LLM non disponible
  - Logique dans main.py : texte ‚Üí LLM texte, image ‚Üí Vision LLM ou OCR fallback

- **Prompts externalis√©s** :
  - Dossier `src/prompts/` avec fichiers .txt s√©par√©s
  - `cv_extraction_text.txt` : prompt pour extraction texte
  - `cv_extraction_vision.txt` : prompt pour extraction images
  - `__init__.py` avec `load_prompt()`, `get_cv_text_prompt()`, `get_cv_vision_prompt()`
  - Prompts traduits en fran√ßais
  - R√®gle exp√©riences : 1 mission = 1 entr√©e (d√©coupage si trop long)

- **UI Toggle/Edit sur ExtractedLines** :
  - Toggle switch actif/inactif (vert/rouge) sur chaque ligne extraite
  - Bouton √©dition (pictogramme crayon)
  - Endpoint `line/toggle/<int:line_id>/` avec `extracted_line_toggle_view`
  - JavaScript pour appels API et mise √† jour visuelle
  - `resumeProcessingCVs()` pour reprendre le polling des CVs "En cours" au chargement

- **D√©pendances ajout√©es** :
  - requirements.txt : `pdf2image`, `pytesseract`, `Pillow`
  - Dockerfile : `poppler-utils`, `tesseract-ocr`, `tesseract-ocr-fra`, `tesseract-ocr-eng`

**Probl√®mes rencontr√©s:**
- **CV stuck "En cours..."** apr√®s page reload
  - Cause : polling interrompu par le reload avant r√©ception du status "completed"
  - Solution : `resumeProcessingCVs()` qui reprend le polling pour les CVs avec `data-status="processing"`
- **docker-compose KeyError 'ContainerConfig'**
  - Cause : bug docker-compose avec rebuild
  - Solution : `docker-compose stop && rm -f && up` au lieu de `up -d` direct

**D√©cisions techniques:**
- **Vision LLM natif plut√¥t qu'OCR seul** : meilleure qualit√© d'extraction, compr√©hension du layout
- **OCR en fallback** : Tesseract si le provider LLM ne supporte pas la vision
- **Prompts en fichiers .txt** : facilite l'it√©ration et le versioning des prompts
- **D√©coupage exp√©riences** : 1 mission = 1 entr√©e pour granularit√© fine dans le matching
- **Prompt en fran√ßais** : le LLM comprend mieux le contexte des CVs fran√ßais

---

### 2025-12-22 (9) - Int√©gration GUI ‚Üî cv-ingestion + Polling asynchrone + Suppression CV
**Contexte:** Connecter la GUI Django au microservice cv-ingestion en mode Docker, impl√©menter le polling asynchrone pour les traitements longs, et ajouter la suppression des CVs

**R√©alisations:**
- **Configuration Docker multi-service** :
  - docker-compose.yml : context root pour acc√®s au package shared
  - app/cv-ingestion/Dockerfile : copie shared/ et install pip
  - app/gui/Dockerfile : adapt√© pour context root
  - env_file dans docker-compose pour charger app/cv-ingestion/.env
  - Ports expos√©s via variables : GUI_PORT=8085, DB_PORT=5433

- **Configuration environnement** :
  - `.env` root avec config commune (DATABASE_URL, ports, URLs inter-services)
  - `.envrc` pour direnv (charge tous les .env du projet)
  - `app/cv-ingestion/.env` : LLM_TYPE=ollama, LLM_ENDPOINT=http://ollama.molp.fr/v1

- **Polling asynchrone cv-ingestion** (pattern async/polling) :
  - `task_store.py` : store en m√©moire thread-safe (TaskStatus enum, Task dataclass)
  - `POST /extract/async` : retourne imm√©diatement un task_id
  - `GET /extract/status/{task_id}` : retourne pending/processing/completed/failed
  - BackgroundTasks FastAPI pour traitement asynchrone
  - Ancien endpoint synchrone `/extract` conserv√© pour r√©trocompatibilit√©

- **Int√©gration GUI polling** :
  - `cv_upload_view` : appelle `/extract/async`, retourne task_id au frontend
  - `cv_status_view` : nouvelle vue pour polling depuis le frontend
  - Mod√®le CV : ajout champ `task_id` (migration 0003)
  - JavaScript : polling toutes les 2s avec messages de progression dynamiques
  - Timeout max 4 minutes (MAX_POLL_ATTEMPTS=120)

- **Suppression CV** :
  - `cv_delete_view` : endpoint DELETE/POST pour supprimer un CV
  - Supprime le fichier du storage + cascade sur ExtractedLines
  - Modal de confirmation avec nom du CV
  - Bouton corbeille sur chaque document dans la liste

- **Navigation par hash URL** :
  - `showSection()` met √† jour `window.location.hash` avec `history.replaceState()`
  - Au chargement de la page, lecture du hash pour restaurer la section active
  - Apr√®s upload/suppression CV : `window.location.hash = 'documents'` avant reload
  - Permet de rester sur la bonne section apr√®s n'importe quelle action

**Probl√®mes rencontr√©s:**
- **`shared` package not found** en Docker build
  - Cause : context `./app/cv-ingestion` n'inclut pas `../../shared`
  - Solution : context `.` (root) + `COPY shared/` dans Dockerfile
- **Port 5432 already allocated**
  - Cause : PostgreSQL local d√©j√† sur le port
  - Solution : DB_PORT=5433 dans .env
- **Port 8080 already allocated**
  - Cause : autre service sur le port
  - Solution : GUI_PORT=8085 dans .env
- **`LLM_API_KEY is required for OpenAI`** en Docker
  - Cause : Docker ne chargeait pas le .env du service
  - Solution : ajouter `env_file: app/cv-ingestion/.env` dans docker-compose.yml
- **404 Not Found `/chat/completions`** sur Ollama
  - Cause : LLM_ENDPOINT sans `/v1` suffix
  - Solution : `http://ollama.molp.fr/v1` (pas `http://ollama.molp.fr`)
- **Container ne pick up pas les changements .env**
  - Solution : `docker-compose down && docker-compose up -d` (pas juste restart)
- **docker-compose `KeyError: 'ContainerConfig'`**
  - Cause : bug docker-compose avec rebuild
  - Solution : `docker-compose down` puis `up` au lieu de juste `up -d`

**D√©cisions techniques:**
- **Polling plut√¥t que WebSockets** : plus simple, suffisant pour le POC
- **Store en m√©moire** plut√¥t que Redis : simplicit√©, pas de d√©pendance externe
- **BackgroundTasks FastAPI** plut√¥t que Celery : l√©ger, pas de broker √† g√©rer
- **task_id UUID** : unique, non pr√©dictible, pas besoin de s√©quence DB
- **Cascade delete** : supprimer un CV supprime automatiquement ses ExtractedLines

---

### 2025-12-22 (8) - Tests int√©gration cv-ingestion + Package shared installable
**Contexte:** Tester cv-ingestion avec serveur Ollama distant et rendre le package shared installable

**R√©alisations:**
- **Script de test d'int√©gration** (`scripts/test_integration.py`) :
  - Test extraction PDF (pdfplumber)
  - Test analyse LLM avec Ollama distant (`llm.molp.fr`)
  - Test√© avec plusieurs mod√®les : llama3.1:8b, gpt-oss:20b, gemma3:4b
  - Sortie vers `data_test/output.txt` avec r√©sultats complets
  - Extraction r√©ussie : 22-45 lignes selon le mod√®le

- **Package shared installable** (`shared/`) :
  - Structure `shared/src/shared/` pour package pip standard
  - `pyproject.toml` avec setuptools
  - Installation via `pip install -e ../../shared` dans requirements.txt
  - Plus besoin de PYTHONPATH pour les imports
  - Microservices vraiment ind√©pendants

- **Fix CI check-branch** :
  - Job ne se d√©clenchait pas correctement (github.head_ref vide sur push)
  - Ajout condition `if: github.event_name == 'pull_request' && github.base_ref == 'main'`
  - Maintenant le check ne tourne que pour les PRs vers main

- **Interfaces partag√©es cr√©√©es** :
  - `shared.constants.ContentType` : enum pour CV et offres
  - `shared.interfaces.ExtractedLine` : ligne extraite avec type et ordre
  - `shared.interfaces.CVData` : donn√©es CV avec helpers (skills_hard, experiences, etc.)
  - `shared.interfaces.ServiceHealth` : health check standard

**Probl√®mes rencontr√©s:**
- **ModuleNotFoundError: No module named 'shared'** lors du lancement serveur
  - Cause : PYTHONPATH non configur√©
  - Solution : transformer shared en package pip installable
- **Structure package incorrecte** : hatchling vs setuptools
  - Solution : utiliser setuptools avec structure `src/shared/`
- **CI check-branch ex√©cut√© sur push** : `github.head_ref` vide sur event push
  - Solution : ajouter condition `if: github.event_name == 'pull_request' && github.base_ref == 'main'`

**Commandes utiles:**
- Supprimer branche locale : `git branch -d feature/matthieu-cv-ingestion`
- Supprimer branche distante : `git push origin --delete feature/matthieu-cv-ingestion`

**Workflow Ruff + Git (commandes essentielles):**
```bash
# 1. Checker les erreurs (sans modifier)
ruff check .

# 2. Auto-fix ce qui peut l'√™tre + formatter
ruff check --fix . && ruff format .

# 3. Stage + commit + push (one-liner)
ruff check --fix . && ruff format . && git add -A && git commit -m "message" && git push

# Si le commit √©choue √† cause du pre-commit hook (trailing whitespace, etc.) :
# ‚Üí Les fichiers modifi√©s par le hook sont "unstaged"
# ‚Üí Solution : re-stage et re-commit
git add -A && git commit -m "message"
```

**D√©cisions techniques:**
- **Package pip installable** plut√¥t que PYTHONPATH : vraie ind√©pendance des microservices
- **Mode √©ditable** (`-e`) : modifications shared refl√©t√©es sans r√©installation
- **Helpers dans CVData** : `skills_hard`, `experiences`, `get_by_type()` pour faciliter l'usage

---

### 2025-12-22 (7) - Microservice cv-ingestion + Migration Ruff
**Contexte:** Impl√©menter le microservice cv-ingestion et migrer les outils de linting vers Ruff

**R√©alisations:**
- **Microservice cv-ingestion complet** :
  - FastAPI sur port 8081 (standalone, pas Django)
  - Extraction PDF (pdfplumber + PyMuPDF)
  - Extraction DOCX (python-docx)
  - LLM provider-agnostic avec Factory Pattern :
    - `OpenAIProvider` (OpenAI + OpenAI-compatible APIs)
    - `AnthropicProvider` (Claude)
    - `OllamaProvider` (local, utilise API compatible OpenAI)
  - Configuration via env vars : LLM_TYPE, LLM_ENDPOINT, LLM_API_KEY, LLM_MODEL
  - Endpoint POST /extract avec validation fichier
  - Dockerfile et .env.example

- **Migration pre-commit vers Ruff** :
  - Remplacement de black, isort, flake8, mypy par Ruff
  - Configuration dans pyproject.toml (line-length=120, Python 3.12)
  - R√®gles activ√©es : E, W, F, I, B, C4, UP, SIM
  - CI mis √† jour avec job lint Ruff d√©di√©
  - Documentation pre_commit_101.md mise √† jour

**Probl√®mes rencontr√©s:**
- **Bandit B104** : "Possible binding to all interfaces" sur `0.0.0.0`
  - Solution : `# nosec B104 - Docker container` (faux positif pour conteneur)
- **Ruff B904** : "raise ... from err" dans except clause
  - Solution : `raise HTTPException(...) from e`
- **mypy bloquait le CI** pour membres sans assistant de code
  - Solution : migration compl√®te vers Ruff (plus simple, plus rapide)

**D√©cisions techniques:**
- **cv-ingestion isol√©** : microservice ind√©pendant, ne partage pas la DB Django
- **Factory Pattern LLM** : permet de changer de provider sans modifier le code m√©tier
- **Ruff plut√¥t que black+isort+flake8+mypy** : 1 outil au lieu de 4, 10-100x plus rapide
- **bandit conserv√©** : Ruff ne fait pas l'analyse s√©curit√©
- **gitleaks conserv√©** : d√©tection des secrets

---

### 2025-12-22 (6) - Convention de langue (code EN / UI FR)
**Contexte:** Standardiser les conventions de langue dans le projet

**R√©alisations:**
- Cr√©ation de CLAUDE.md avec les r√®gles de langue :
  - Commentaires code : anglais
  - Messages commit : anglais (apr√®s pr√©fixe [CortexForge])
  - Noms variables/fonctions/classes : anglais
  - Contenu UI visible : fran√ßais
- Refactoring de tous les fichiers existants :
  - views.py : 1 commentaire FR ‚Üí EN
  - profile.html : tous les commentaires CSS/HTML/JS ‚Üí EN
  - home.html : tous les commentaires CSS/HTML ‚Üí EN
- V√©rification models.py et admin.py (d√©j√† conformes)

**Probl√®mes rencontr√©s:**
- Tentative d'ajout dans .claude/settings.json √©chou√©e (validation error: "Property code_style is not allowed")
- Solution : utiliser CLAUDE.md qui est le bon endroit pour les instructions Claude

**D√©cisions techniques:**
- **CLAUDE.md** : fichier central pour les instructions de style/conventions
- **S√©paration claire** : code interne EN, interface utilisateur FR
- **verbose_name Django** : reste en FR car c'est affich√© dans l'admin (UI)

---

### 2025-12-22 (5) - ORM CV/ExtractedLine + Sp√©cification cv-ingestion
**Contexte:** Impl√©menter l'ORM pour CV et ExtractedLine, connecter la vue profil aux donn√©es, √©crire les specs du service cv-ingestion

**R√©alisations:**
- Mod√®les Django : CV, CoverLetter, ExtractedLine dans accounts/models.py
- ExtractedLine avec content_type (experience, education, skill_hard, skill_soft, certification, language, interest, summary, other)
- CV avec extraction_status (pending, processing, completed, failed)
- Migration 0002_add_cv_coverletter_extractedline appliqu√©e
- Vue profile_view connect√©e aux ExtractedLine (querysets par content_type)
- Template profile.html avec affichage conditionnel des donn√©es
- Sp√©cification compl√®te cv-ingestion dans docs/cv_ingestion_spec.md :
  - Architecture et flux de traitement
  - Extraction texte (PDF/DOCX)
  - Analyse LLM avec prompt et schema JSON
  - API endpoints
  - Configuration, erreurs, s√©curit√©, tests, roadmap

**Probl√®mes rencontr√©s:**
- "no such table: accounts_extractedline" ‚Üí migration 0002 non appliqu√©e, r√©solu avec `python manage.py migrate`
- Donn√©es vides dans "Parcours professionnel" ‚Üí normal, sera peupl√© par cv-ingestion

**D√©cisions techniques:**
- **ExtractedLine granulaire** : 1 ligne = 1 unit√© (1 poste, 1 comp√©tence, 1 dipl√¥me)
- **Tabs "Parcours professionnel"** : mappent directement aux content_types ExtractedLine
- **LLM extraction** : prompt structur√© avec JSON schema pour sortie standardis√©e
- **cv-ingestion en microservice** : d√©clenchement async via queue (Celery future)

---

### 2025-12-22 (4) - Refonte UI Landing Page et Profil
**Contexte:** Am√©liorer l'interface utilisateur de la landing page et de la page profil

**R√©alisations:**
- Landing page dynamique avec animations CSS (fadeInUp, float, pulse, slideIn)
- Hero section plein √©cran (100vh) sans scroll
- Navbar conditionnelle : masqu√©e si d√©connect√©, visible si connect√©
- Cartes de "match preview" anim√©es dans le hero
- Stats anim√©es avec gradient (10K+ offres, 95% pr√©cision, 30s pour matcher)
- Page profil avec sidebar menu (photo, donn√©es perso, CVs, LM, pitch, succ√®s, hobbies)
- Site non-scrollable (overflow: hidden sur body)
- Ajustement it√©ratif des tailles pour tenir dans le viewport

**Probl√®mes rencontr√©s:**
- Migration Django manquante ‚Üí `makemigrations accounts` pour cr√©er 0001_initial.py
- Lignes trop longues dans migration (flake8 E501) ‚Üí split help_text avec parenth√®ses
- Django 5+ logout n√©cessite POST ‚Üí form avec csrf_token au lieu de lien

**D√©cisions techniques:**
- **CSS-only animations** : pas de JS pour les animations, tout en CSS
- **Template blocks conditionnels** : `{% block navbar %}` avec `{{ block.super }}` pour h√©ritage s√©lectif
- **`{% block main_attrs %}`** : permet de customiser les attributs de `<main>` par template
- **clamp() pour responsive** : `font-size: clamp(2.8rem, 5.5vw, 4rem)` adapte la taille au viewport

---

### 2025-12-22 (3) - Configuration multi-environnement
**Contexte:** Permettre au service GUI de tourner en local, Docker dev et Cloud Run prod

**R√©alisations:**
- Settings Django avec `ENV_MODE` (local/dev/prod)
- Mode local : `run_local.sh` avec SQLite
- Mode Docker dev : `docker-compose.dev.yml` avec PostgreSQL + hot-reload
- Mode Docker prod : `Dockerfile.prod` multi-stage optimis√©
- CI/CD GCloud : `cloudbuild.yaml` pour Cloud Run
- Support Cloud SQL via Unix socket
- Support Cloud Storage pour les uploads (media)
- WhiteNoise pour les fichiers statiques
- README.md avec documentation des 3 modes

**D√©cisions techniques:**
- **Cloud Run** (serverless) plut√¥t que GKE (Kubernetes) pour simplifier
- **Cloud SQL PostgreSQL** pour la prod
- **Cloud Storage** pour les uploads CV
- **Multi-stage build** pour image prod l√©g√®re
- **WhiteNoise** pour servir les static files sans nginx

---

### 2025-12-22 (2) - Service GUI Django
**Contexte:** Impl√©mentation du service GUI avec Django

**R√©alisations:**
- Choix framework : Django (malgr√© architecture microservices, pour batteries incluses)
- Cr√©ation projet Django dans `app/gui/`
- App `accounts` avec custom User model :
  - Inscription, connexion, d√©connexion
  - Profil utilisateur (pr√©f√©rences emploi : salaire, disponibilit√©, remote)
  - Suppression compte (RGPD)
- Templates Bootstrap 5 (base.html, home, login, register, profile)
- Configuration PostgreSQL via variables d'environnement
- Dockerfile pour le service GUI
- User Stories POC couvertes : US001, US002, US005, US006, US007, US008

**D√©cisions techniques:**
- **Django vs FastAPI** : Django choisi pour auth int√©gr√©e et admin
- **Custom User Model** : email comme USERNAME_FIELD
- **Bootstrap 5 via CDN** : rapidit√© de d√©veloppement pour POC

---

### 2025-12-22 (1) - Initialisation projet + Architecture microservices
**Contexte:** D√©marrage du projet JobMatch - plateforme de matching CV/offres d'emploi

**R√©alisations:**
- Lecture et analyse des documents de contexte (One liner.pdf, Job match.xlsx)
- Compr√©hension de la vision produit (V1 MVP ‚Üí V2 avec personnalisation CV)
- Identification de l'√©quipe (Matthieu, Cl√©ment, Mohamed, Maxime)
- Cr√©ation du fichier POSTMORTEM.md et PITCH.md
- Mise en place architecture microservices :
  - `app/gui` - Interface utilisateur
  - `app/cv-ingestion` - Import et parsing CV
  - `app/offre-ingestion` - R√©cup√©ration offres (France Travail)
  - `app/matching` - Algorithme de matching
  - `shared/` - Code partag√© (interfaces, constants, utils)
- Configuration CI/CD :
  - `.pre-commit-config.yaml` (black, isort, flake8, mypy, bandit, gitleaks)
  - `.github/workflows/ci.yml` (tests par service)
  - `.github/workflows/cd.yml` (build Docker + deploy)
- `docker-compose.yml` avec postgres + redis
- Gestion Git : branche `dev` cr√©√©e, `DEV_POC` merg√©e et supprim√©e

**Probl√®mes rencontr√©s:**
- Fichier Excel non lisible directement ‚Üí r√©solu avec pandas + openpyxl
- Pre-commit `types-all` incompatible Python 3.12 ‚Üí retir√© de mypy config
- Hook `no-commit-to-branch` bloquait merge sur dev ‚Üí retir√© dev des branches prot√©g√©es

**D√©cisions techniques:**
- **Mode vibecoding + √©quipe classique** : configuration dans `.claude/settings.json`
- **Pr√©fixe commits** : `[CortexForge]` (pas de footer "Generated by Claude Code")
- **P√©rim√®tre Matthieu** : gui, cv-ingestion, frontend, shared/utils
- **Zones interdites** : offre-ingestion, matching (√©quipe classique)
- **Branches prot√©g√©es** : main uniquement (dev autoris√© pour permettre les merges)

## üß† Apprentissages cl√©s
- Le projet a deux versions : V1 (matching simple) et V2 (matching + personnalisation CV)
- POC structur√© en 4 domaines : Gestion Compte (DE:0), Import CV (DE:1), Ingestion Offres (DE:2), Smart Match (DE:2)
- Priorit√©s MoSCoW d√©finies dans les User Stories
- Mode vibecoding en √©quipe n√©cessite un p√©rim√®tre clair et des r√®gles strictes
- Django 5+ : logout doit √™tre en POST (plus de GET)
- Template blocks Django : `{{ block.super }}` pour h√©riter conditionnellement
- **CLAUDE.md** est le bon endroit pour les conventions de style (pas settings.json)
- S√©paration langue : code EN pour maintenabilit√© internationale, UI FR pour les utilisateurs
- **Ruff** remplace 4 outils Python (black, isort, flake8, mypy) et est 10-100x plus rapide
- **Factory Pattern** pour LLM providers : permet de switcher OpenAI/Anthropic/Ollama sans changer le code
- **Microservices isol√©s** : ne partagent pas de DB, communiquent uniquement par API
- **Package pip installable** pour shared : `pip install -e ../../shared` dans requirements.txt
- **Structure package Python** : `shared/src/shared/` avec setuptools pour imports propres
- **Polling async** : pattern simple et robuste pour les traitements longs (pr√©f√©rer √† WebSockets pour POC)
- **BackgroundTasks FastAPI** : alternative l√©g√®re √† Celery pour traitement async sans broker
- **docker-compose context root** : n√©cessaire quand un service a besoin de fichiers hors de son dossier
- **env_file vs environment** : env_file charge un fichier .env, environment d√©finit des vars inline
- **Ollama API** : endpoint doit se terminer par `/v1` pour √™tre compatible OpenAI
- **Vision LLM** : GPT-4o, Claude 3+, LLaVA supportent l'analyse d'images nativement
- **Prompts externalis√©s** : fichiers .txt s√©par√©s facilitent l'it√©ration sans toucher au code
- **D√©coupage exp√©riences CV** : 1 mission = 1 entr√©e pour un matching plus pr√©cis
- **pdf2image + poppler** : conversion PDF ‚Üí images pour Vision LLM ou OCR
- **Multi-form pattern Django** : `form_type` hidden field pour g√©rer plusieurs forms sur une page
- **Re-login apr√®s password change** : appeler `login(request, user)` pour √©viter la d√©connexion
- **get_or_create pour OneToOne** : cr√©e automatiquement la relation si inexistante
- **Export RGPD** : exclure les donn√©es sensibles (API keys) m√™me si l'utilisateur les demande
- **Form fields vs JSON** : pour multipart/form-data avec fichier, utiliser Form() pas Body()
- **Restriction fonctionnalit√©s par tier** : double v√©rification c√¥t√© serveur ET c√¥t√© template
- **Modal pricing** : CSS natif avec backdrop-filter pour blur, pas besoin de lib JS
- **Cropper.js** : biblioth√®que la plus mature pour recadrage d'images (utilis√©e par LinkedIn)
- **Port interne vs externe Docker** : `5433:5432` signifie port 5433 expos√© sur l'h√¥te, port 5432 interne au r√©seau Docker
- **TemplateView vs custom View** : pour passer du contexte dynamique (queries DB), il faut une vue personnalis√©e
- **get_or_create** : pattern idempotent pour √©viter les erreurs IntegrityError sur les contraintes uniques
- **docker cp** : permet de copier des fichiers du container vers l'h√¥te (utile pour r√©cup√©rer des migrations g√©n√©r√©es)
- **Two-step modal** : s√©pare la s√©lection de l'√©dition pour une meilleure UX
- **Canvas toBlob** : conversion c√¥t√© client avant upload pour optimiser la bande passante
- **requirements-dev.txt** : permet d'avoir des d√©pendances uniquement pour le dev local
- **Conditional INSTALLED_APPS** : `if ENV_MODE == "local"` + try/except pour apps optionnelles
- **parse_llm_response() extensible** : chaque content_type avec des champs structur√©s n√©cessite sa propre branche elif
- **Rendu manuel checkboxes Django** : pour un contr√¥le CSS total, utiliser `{% for choice in form.field %}{{ choice.tag }}{% endfor %}` au lieu de `{{ form.field }}`
- **Microservices FastAPI identiques** : dupliquer le pattern de cv-ingestion pour nouveaux services (task_store, providers, schemas)
- **MutationObserver** : permet d'initialiser des composants JS quand une section devient visible (lazy init)
- **Prompt engineering STAR** : instructions claires pour guider progressivement S‚ÜíT‚ÜíA‚ÜíR
- **Context snapshot** : sauvegarder le contexte utilisateur au d√©but de la conversation pour coh√©rence
- **Architecture g√©n√©rique pour coaching** : utiliser un `coaching_type` enum permet d'√©tendre facilement le module √† d'autres types de coaching
- **Donn√©es conditionnelles selon le type** : `_build_user_context(coaching_type)` enrichit les donn√©es en fonction du besoin (pitch = donn√©es STAR compl√®tes)
- **Prompts s√©par√©s par type** : un fichier .txt par type de coaching pour faciliter l'it√©ration
- **SSE Streaming** : Server-Sent Events avec format `data: {...}\n\n` pour affichage temps r√©el
- **ReadableStream API** : `response.body.getReader()` + `TextDecoder` pour parser les chunks SSE en JavaScript
- **Django StreamingHttpResponse** : permet de proxyer un stream SSE depuis un service externe
- **Proxy streaming Django** : accumule le contenu pour sauvegarder la r√©ponse compl√®te en base apr√®s le stream
- **LLM streaming** : OpenAI `stream=True`, Anthropic `messages.stream()` context manager
- **Headers SSE** : `Cache-Control: no-cache`, `X-Accel-Buffering: no` pour √©viter le buffering nginx
- **marked.js pour markdown** : biblioth√®que standard l√©g√®re pour parser le markdown des r√©ponses LLM
- **Streaming + markdown** : accumuler en `textContent` pendant le stream, appliquer `marked.parse()` une seule fois √† la fin
- **Chat expandable** : CSS `position: absolute` avec classe toggle pour superposer un √©l√©ment sur son voisin
- **Marqueur de fin stream** : `[MARKER]` + JSON dans le prompt permet d'extraire des donn√©es structur√©es du stream SSE sans second appel LLM
- **Prompt engineering strict** : exemples MAUVAIS/BON explicites pour contraindre le comportement verbeux des LLM
- **Phases s√©quentielles en prompt** : "n'√©voque JAMAIS la phase suivante" emp√™che le LLM de sauter des √©tapes
- **docx.js browser** : utiliser le build UMD (`index.umd.js`) et non ESM ou min pour compatibilit√© script tag
- **contextlib.suppress** : remplace `try/except/pass` de fa√ßon plus idiomatique (r√®gle Ruff SIM105)
- **yield from vs try/except** : `yield from` ne peut pas √™tre utilis√© dans un try/except car les exceptions du g√©n√©rateur ne seraient pas catch√©es
- **noqa avec explication** : toujours documenter pourquoi une r√®gle est ignor√©e (ex: `# noqa: UP028 - yield from incompatible with try/except`)
- **Bandit vs Ruff syntaxe** : Bandit utilise `# nosec BXXX`, Ruff utilise `# noqa: SXXX` - ce sont des outils diff√©rents avec syntaxes diff√©rentes
- **Django QuerySet.first()** : retourne `None` si pas de r√©sultat, ne l√®ve jamais d'exception - pas besoin de try/except
- **drf-spectacular** : documentation OpenAPI 3 automatique pour Django REST Framework, plus moderne que drf-yasg
- **Auto-cr√©ation mod√®les li√©s** : cr√©er les mod√®les d√©pendants (Application) directement dans la vue API d'import pour simplifier le workflow
- **JSONField pour history** : simple et efficace pour un event log sans n√©cessiter une table s√©par√©e
- **pgvector** : extension PostgreSQL pour recherche vectorielle, index HNSW pour performances (remplace Faiss/Milvus)
- **Mod√®le Django `managed=False`** : permet de lire une table cr√©√©e par un autre service sans que Django la g√®re
- **Cache lazy refresh** : TTL simple avec invalidation explicite, plus simple que refresh proactif
- **GCP Cloud Run** : serverless containers, scale to zero, id√©al pour microservices avec trafic variable
- **Vertex AI text-embedding-004** : embeddings Google optimis√©s pour fran√ßais, alternative √† sentence-transformers
- **MLflow pour fine-tuning uniquement** : overkill pour mod√®les pre-trained, utile pour experiment tracking et model registry
- **Contrastive learning** : technique de fine-tuning embeddings avec triplets (anchor, positive, negative)
- **Cross-encoder** : mod√®le de re-ranking plus pr√©cis que bi-encoder, utilis√© en second stage
- **Learning to Rank** : approche ML pour optimiser l'ordre des r√©sultats de recherche
- **OfferInteraction pattern** : collecter les interactions utilisateur (vues, clics, applications) pour supervision implicite
- **wkhtmltopdf** : g√©n√©ration PDF depuis HTML sans LaTeX, supporte unicode nativement
- **Base de donn√©es partag√©e dev** : utiliser le m√™me PostgreSQL en local et Docker via port expos√© (ex: `localhost:5433`)
- **Script dev interactif** : menu bash avec couleurs + mode CLI rapide pour les commandes fr√©quentes
- **`set +e` en bash** : permet de continuer m√™me si une commande √©choue (utile pour services manquants)
- **`asyncio.create_task()` vs `BackgroundTasks`** : BackgroundTasks de FastAPI n'est PAS vraiment async - il attend la fin de la fonction avant de renvoyer la r√©ponse HTTP. Utiliser `asyncio.create_task()` pour une vraie ex√©cution non-bloquante
- **`asyncio.to_thread()` pour appels synchrones** : Les SDKs LLM (OpenAI, Anthropic) sont synchrones et bloquent l'event loop. Wrapper avec `await asyncio.to_thread(fn, args)` pour ex√©cuter dans un thread pool
- **Pattern task_id + polling** : Pour les traitements longs (>10s), retourner imm√©diatement un task_id et laisser le client faire du polling sur `/status/{task_id}`
- **ATS optimization** : L'intitul√© du CV doit √™tre tr√®s proche du titre de l'offre, et reprendre les mots-cl√©s exacts (pas de synonymes)

## ‚ö†Ô∏è Pi√®ges √† √©viter
- Ne pas oublier la conformit√© RGPD (t√¢che assign√©e √† Maxime)
- Gentleman Agreement √† signer avant de continuer
- **Vibecoding** : ne jamais modifier les zones de l'√©quipe classique (offre-ingestion, matching)
- Toujours confirmer avant de modifier fichiers partag√©s (docker-compose, .env, interfaces)
- **Migrations auto-g√©n√©r√©es** : peuvent avoir des lignes trop longues (flake8 E501), n√©cessite reformatage manuel
- **overflow: hidden** sur body emp√™che tout scroll, s'assurer que le contenu tient dans le viewport
- **Bandit B104** : `host="0.0.0.0"` g√©n√®re un warning, ajouter `# nosec B104` pour les conteneurs Docker
- **Ruff B904** : dans un `except`, utiliser `raise ... from e` ou `raise ... from None`
- **Import shared sans pip install** : ne pas oublier d'installer le package avant de lancer les microservices
- **Structure package** : bien utiliser `src/package/` pour que setuptools trouve les modules
- **Docker .env changes** : `docker-compose restart` ne relit pas les .env, utiliser `down` puis `up`
- **Ollama endpoint** : toujours ajouter `/v1` √† l'URL de base pour compatibilit√© OpenAI
- **docker-compose context** : si un service a besoin de `../../shared`, mettre context √† `.` (root)
- **KeyError ContainerConfig** : bug docker-compose, r√©soudre avec `down` complet avant `up`
- **Page reload perd la section active** : utiliser URL hash (`#section`) pour persister l'√©tat
- **Polling interrompu par reload** : impl√©menter `resumeProcessingCVs()` pour reprendre au chargement
- **PDF scann√©s sans texte** : pdfplumber retourne vide, utiliser Vision LLM ou OCR
- **Prompts trop longs dans le code** : externaliser en fichiers .txt pour maintenabilit√©
- **Pre-commit hooks modifient les fichiers** : les hooks (trailing whitespace, Ruff, etc.) peuvent modifier les fichiers staged, ce qui les "unstage" et fait √©chouer le commit. Solution : `git add -A && git commit` pour re-stage et recommit
- **offre-ingestion sans Dockerfile** : `docker-compose build` √©choue si un service est d√©clar√© sans Dockerfile
  - Solution : builder explicitement les services existants : `docker-compose build gui cv-ingestion`
- **Django app optionnelle en production** : ne jamais mettre une app dev-only dans INSTALLED_APPS sans condition
  - Solution : `if ENV_MODE == "local": try: import app; INSTALLED_APPS.append(...)`
- **Nouveaux content_types structur√©s** : lors de l'ajout d'un content_type avec des champs structur√©s (comme personal_info ou social_link), ne pas oublier d'ajouter le parsing dans `parse_llm_response()` dans analyzer.py
- **Django CheckboxSelectMultiple** : le widget g√©n√®re un `<ul><li>` avec styles qui peuvent override le CSS. Pr√©f√©rer le rendu manuel pour un contr√¥le total du layout
- **docx.js CDN jsdelivr** : le path `build/index.min.js` n'existe pas toujours, utiliser unpkg avec `build/index.umd.js` pour browser
- **yield from dans try/except** : Ruff UP028 sugg√®re `yield from` mais cela emp√™che de catch les erreurs et faire un fallback - utiliser `# noqa: UP028`
- **Bandit `# noqa` ne fonctionne pas** : Bandit ignore la syntaxe `# noqa: SXXX`, utiliser `# nosec BXXX` √† la place
- **try/except/pass sur QuerySet** : `.filter().first()` ne l√®ve pas d'exception, retourne `None` - Bandit B110 d√©tecte ce pattern inutile
- **SQLite vs PostgreSQL en dev** : utiliser des bases diff√©rentes entre local et Docker cause des pertes de donn√©es et incoh√©rences
- **ENV_MODE manquant dans docker-compose.yml** : sans `ENV_MODE=dev`, Django utilise le mode "local" qui essaie de se connecter √† `localhost:5433` (inaccessible depuis le container)
- **Migrations cr√©√©es dans le container** : si `makemigrations` est ex√©cut√© dans le container, le fichier de migration n'existe pas dans le code source ‚Üí utiliser `docker cp` pour r√©cup√©rer
- **Volume Docker vs base vide** : `docker-compose down` sans `-v` pr√©serve les donn√©es, mais un `full-restart` d'un service ne recr√©e pas les users ‚Üí cr√©er un superuser apr√®s reset
- **`docker-compose down -v`** : le flag `-v` supprime les volumes = perte de toutes les donn√©es. Ne jamais utiliser sauf pour reset complet
- **FastAPI BackgroundTasks pour async** : NE PAS utiliser pour les t√¢ches longues car elles bloquent quand m√™me la r√©ponse HTTP. Utiliser `asyncio.create_task()` √† la place
- **Async functions avec appels synchrones** : Marquer une fonction `async` ne la rend pas non-bloquante si elle appelle du code synchrone. Utiliser `asyncio.to_thread()` pour wrapper les appels bloquants
- **Timeout court sur POST de d√©marrage** : Le POST qui lance une t√¢che async doit retourner en <1s. Si √ßa prend plus longtemps, v√©rifier que la t√¢che n'est pas ex√©cut√©e de mani√®re synchrone
- **Django `mark_safe()` sans sanitization** : Bandit B703/B308 d√©tecte les risques XSS.
  - **Probl√®me r√©el** : `mark_safe()` sur du contenu utilisateur = faille XSS critique (injection de `<script>`)
  - **Faux positif** : Bandit ne peut pas savoir si le contenu est sanitiz√©, il alerte toujours
  - **Solution** : sanitizer avec `bleach.clean()` avant `mark_safe()` avec whitelist stricte de tags/attributs, puis ajouter `# nosec B308 B703` avec un commentaire expliquant pourquoi c'est s√©curis√©
  - **Exemple** : `return mark_safe(bleach.clean(html, tags=ALLOWED_TAGS))  # nosec B308 B703`
- **Exemples JWT dans la documentation** : Gitleaks d√©tecte les tokens JWT m√™me fictifs comme secrets.
  - **Probl√®me r√©el** : aucun, ce sont des exemples de documentation, pas de vrais tokens
  - **Faux positif** : Gitleaks ne distingue pas les exemples des vrais secrets
  - **Solution** : utiliser des placeholders explicites comme `<JWT_ACCESS_TOKEN>` au lieu de vrais formats JWT `eyJ0eXAi...`
- **Ollama API OpenAI-compatible vs native** : Ollama expose deux APIs diff√©rentes :
  - `/api/tags`, `/api/generate`, `/api/chat` : API native Ollama
  - `/v1/models`, `/v1/chat/completions` : API OpenAI-compatible
  - **Probl√®me** : `/api/tags` peut lister des mod√®les alors que `/v1/models` retourne une liste vide
  - **Cause** : Les mod√®les doivent √™tre explicitement expos√©s via l'API OpenAI-compatible (config Ollama)
  - **Solution** : V√©rifier les deux endpoints, ou adapter le code pour utiliser l'API native Ollama si n√©cessaire
- **GCP Billing account not found** : l'erreur `Billing account for project 'xxx' is not found` survient quand on essaie d'activer des APIs avant d'avoir li√© un compte de facturation au projet.
  - **Pr√©requis obligatoire** : Console GCP ‚Üí Facturation ‚Üí Associer le projet au compte de facturation
  - **Ordre** : 1) Cr√©er projet, 2) Activer facturation, 3) Activer APIs
- **Terraform ne d√©ploie pas le code** : Terraform g√®re l'infrastructure, PAS le code applicatif. Si l'architecture n'a pas chang√©, `terraform apply` ne fait rien m√™me si le code a chang√©.
  - **Probl√®me** : Docker peut utiliser des layers cach√©es et ne pas int√©grer le nouveau code
  - **Solution** : Dans le workflow de d√©ploiement, utiliser `docker compose build --no-cache --pull` pour forcer la reconstruction
  - **Workflow correct** : `build --no-cache` ‚Üí `down` ‚Üí `up -d`
- **Variable d'environnement non d√©finie dans gsutil** : `gsutil mb gs://bucket-name-$PROJECT_ID` √©choue avec "Invalid bucket name" si `$PROJECT_ID` n'est pas d√©fini.
  - **Solution 1** : `export PROJECT_ID=mon-projet-id` avant la commande
  - **Solution 2** : Hardcoder le nom du bucket directement dans les fichiers Terraform
- **Deux types d'authentification gcloud** : `gcloud auth login` et `gcloud auth application-default login` sont DIFF√âRENTS.
  - `gcloud auth login` : Authentifie le CLI gcloud (pour les commandes `gcloud`, `gsutil`)
  - `gcloud auth application-default login` : Cr√©e les credentials pour les SDKs (Terraform, Python, etc.)
  - **Pi√®ge** : Faire `gcloud auth login` ne suffit pas pour Terraform, il faut aussi `gcloud auth application-default login`
- **Zone GCP indisponible** : Certains types de VM ne sont pas disponibles dans toutes les zones.
  - **Sympt√¥me** : `e2-standard-2 VM instance is currently unavailable in the europe-west9-b zone`
  - **Solution** : Utiliser `data.google_compute_zones.available` pour s√©lectionner automatiquement une zone disponible
- **terraform import pour ressources existantes** : Si une ressource existe dans GCP mais pas dans le state Terraform.
  - **Sympt√¥me** : `Error 409: Already Exists`
  - **Solution** : `terraform import google_bigquery_dataset.gold job-match-v0/jobmatch_gold`
- **GitHub Actions secrets non configur√©s** : Erreur cryptique si les secrets manquent.
  - **Sympt√¥me** : `google-github-actions/auth failed with: must specify exactly one of "workload_identity_provider" or "credentials_json"`
  - **Cause** : Les secrets `GCP_WORKLOAD_IDENTITY_PROVIDER` ou `GCP_DEPLOY_SERVICE_ACCOUNT` ne sont pas d√©finis
  - **Solution** : Configurer tous les secrets dans GitHub Settings ‚Üí Secrets ‚Üí Actions
- **Terraform snap --classic** : Terraform via snap n√©cessite le mode classic.
  - **Sympt√¥me** : `error: This revision of snap "terraform" was published using classic confinement`
  - **Solution** : `sudo snap install terraform --classic`

## üèóÔ∏è Patterns qui fonctionnent
- Documentation structur√©e dans Google Drive
- User Stories avec priorit√©s MoSCoW et crit√®res d'acceptation
- R√©partition des t√¢ches selon les pr√©f√©rences/comp√©tences
- `.claude/settings.json` pour d√©finir les r√®gles de vibecoding
- Pr√©fixe de commit `[CortexForge]` pour identifier les commits vibecoding
- Architecture microservices avec dossiers s√©par√©s par domaine

## D√©pannage git
- Pour bien recr√©er la d√©pendance entre les branches main et dev, il faut bien mettre √† jour la baranche main puis √©craser la branche dev en resettant l'historique de la branche dev avec les commandes suivantes :

```bash
# Se placer sur la branche dev
git checkout dev
# Ecraser l'historique de la branche dev avec celui de la branche main
git reset --hard main
```

### Workflow Git complet (feature branch ‚Üí PR ‚Üí merge)
```bash
# 1. Avant commit : lint et format
ruff check --fix . && ruff format .

# 2. Commit
git add -A && git commit -m "[CortexForge] message"

# 3. Push et cr√©er PR sur GitHub
git push -u origin feature/ma-branche

# 4. Apr√®s merge de la PR : retour sur dev et cleanup
git checkout dev && git pull && git branch -d feature/ma-branche
```
- **CSS clamp()** pour des tailles responsive sans media queries
- **Template blocks conditionnels** avec `{% if user.is_authenticated %}{{ block.super }}{% endif %}`
- **Variables CSS** (`:root`) pour coh√©rence des couleurs/styles
- **Factory Pattern** pour providers interchangeables (LLM, DB, etc.)
- **pydantic-settings** pour config via env vars avec validation
- **Ruff avec --fix** dans pre-commit : auto-correction des erreurs simples
- **URL hash navigation** : `history.replaceState()` + lecture du hash au load pour persister l'√©tat UI
- **Prompts en fichiers .txt** : faciles √† √©diter, versionner, et it√©rer sans toucher au code Python
- **D√©tection auto PDF texte/image** : heuristique simple (min chars) avant de choisir la m√©thode d'extraction
- **Vision LLM + OCR fallback** : robustesse maximale pour tous types de PDF
- **Pre-commit workflow** : `ruff check --fix . && ruff format .` avant chaque commit pour auto-fix et formatage
- **Documentation avant code** : r√©diger ARCHITECTURE.md et IAM_GUIDE.md avant de coder l'infrastructure permet de valider l'approche et facilite la maintenance
- **Workload Identity Federation** : √©vite les cl√©s JSON service account, auth keyless depuis GitHub Actions vers GCP
- **Terraform modules s√©par√©s** : main.tf, variables.tf, network.tf, vm.tf, storage.tf, bigquery.tf, iam.tf, outputs.tf - meilleure lisibilit√© et maintenance
- **Deux workflows GitHub Actions s√©par√©s** : un pour Terraform (infra/), un pour Deploy (app/) - s√©paration claire des responsabilit√©s

## üìã TODO / Dette technique
- [x] Choix de la stack technique ‚Üí architecture microservices Python
- [x] Cr√©er branche feature et commit structure microservices
- [x] Documentation pre-commit (docs/pre_commit_101.md)
- [x] Service GUI Django (accounts app)
- [x] Dockerfile GUI
- [x] Configuration multi-environnement (local/dev/prod)
- [x] CI/CD Cloud Run (cloudbuild.yaml)
- [x] Refonte UI landing page (hero, animations, navbar conditionnelle)
- [x] Page profil avec sidebar menu
- [x] ORM CV/CoverLetter/ExtractedLine
- [x] Connexion vue profil aux ExtractedLine
- [x] Sp√©cification cv-ingestion (docs/cv_ingestion_spec.md)
- [x] Convention de langue (CLAUDE.md) : code EN, UI FR
- [x] **Microservice cv-ingestion Phase 1** : FastAPI, extraction PDF/DOCX, LLM provider-agnostic
- [x] **Migration Ruff** : remplacement black/isort/flake8/mypy par Ruff
- [x] **Documentation pre-commit mise √† jour** avec Ruff
- [ ] Gentleman Agreement √† r√©diger et signer
- [ ] Pr√©sentation GitHub √† faire (Matthieu)
- [ ] √âtat de l'art scientifique (donn√©es, algos, SaaS existants, limites)
- [ ] Se renseigner sur la RGPD (Maxime)
- [ ] Tester `run_local.sh`
- [ ] Tester `docker-compose.dev.yml`
- [ ] Cr√©er projet GCloud + Cloud SQL + Cloud Storage
- [x] D√©finir les interfaces partag√©es (schemas CV, offres) ‚Üí shared package
- [x] **Tester cv-ingestion** avec un vrai CV PDF ‚Üí script test_integration.py
- [x] Int√©grer l'upload de CV dans la GUI (section "Mes documents")
- [ ] Impl√©menter les sections du profil (LM, pitch, succ√®s, hobbies)
- [x] Upload photo de profil avec Cropper.js (recadrage style LinkedIn)
- [x] **Connecter GUI ‚Üí cv-ingestion** : appel API apr√®s upload CV
- [x] **Test API cv-ingestion** : lancer serveur FastAPI et tester endpoint /extract
- [ ] Installer shared dans les autres microservices (offre-ingestion, matching, gui)
- [x] **Polling asynchrone** : cv-ingestion avec task_id + GUI polling
- [x] **Suppression CV** : endpoint + modal de confirmation
- [x] **Navigation hash URL** : conserver la section active apr√®s reload
- [x] **Vision LLM** : support PDF images/scann√©s avec GPT-4o, Claude, LLaVA
- [x] **Prompts externalis√©s** : fichiers .txt dans src/prompts/
- [x] **OCR fallback** : Tesseract si Vision LLM non disponible
- [x] **Toggle/Edit UI** : boutons sur les lignes extraites
- [x] **Page Gestion Compte** : settings avec identit√©, email, password, abonnement, LLM config
- [x] **Export RGPD** : endpoint d'export JSON des donn√©es utilisateur
- [x] **UserLLMConfig model** : permet aux users d'utiliser leur propre LLM
- [x] **LLM Config Fallback** : utilise env vars si config user vide
- [x] **S√©lecteur d'abonnement** : choix du plan dans Account Settings
- [x] **Modal Pricing** : comparaison des plans avec fonctionnalit√©s et tarifs
- [x] **Restriction LLM Config** : disponible uniquement pour Premium+
- [x] **AI Assistant STAR Chatbot** : microservice + UI chat pour formalisation succ√®s professionnels
- [x] **Extension Pitch Coaching** : coaching_type enum, nouveau prompt, donn√©es STAR compl√®tes pour pitch
- [x] **UI Pitch dans profile.html** : interface chat pour section "Mon pitch" (PitchChatbot avec coaching_type=pitch)
- [x] **Mod√®le Pitch Django** : stocker les pitchs 30s/3min g√©n√©r√©s (migration 0012)
- [ ] **Sauvegarde pitch depuis chat** : bouton pour extraire et sauvegarder le pitch g√©n√©r√©
- [ ] **√âdition inline** : permettre de modifier le contenu des lignes extraites
- [ ] **Regroupement exp√©riences** : afficher les missions d'un m√™me poste ensemble dans l'UI
- [ ] **Int√©gration paiement** : Stripe pour les abonnements payants
- [ ] **Validation email** : confirmation par email lors du changement d'adresse
- [x] **Auto-cr√©ation succ√®s STAR** : marqueur `[STAR_COMPLETE]` + extraction JSON + cr√©ation auto en base
- [ ] **Tests E2E chatbot STAR** : tester le flux complet conversation ‚Üí extraction ‚Üí cr√©ation succ√®s
- [x] **Swagger/OpenAPI docs** : drf-spectacular avec `/api/docs/` et `/api/redoc/`
- [x] **Mod√®le Application** : workflow candidature (added ‚Üí in_progress ‚Üí applied ‚Üí interview ‚Üí accepted/rejected)
- [x] **Auto-cr√©ation Application** : chaque ImportedOffer cr√©e automatiquement une Application
- [x] **Page liste candidatures** : cards avec filtrage par status
- [ ] **Page d√©tail candidature** : vue compl√®te avec actions (modifier status, notes, documents)
- [ ] **Int√©grer matching service** : appeler POST /match lors de l'import d'une offre
- [ ] **Restreindre CORS production** : limiter aux IDs d'extensions sp√©cifiques
- [x] **Script dev.sh** : menu interactif + commandes CLI pour le workflow de d√©veloppement
- [x] **Base PostgreSQL partag√©e** : local et Docker utilisent la m√™me base via port expos√©
- [x] **Infrastructure GCP Terraform** : VM, VPC, Cloud Storage, BigQuery, IAM, Workload Identity Federation
- [ ] **Configurer GitHub Secrets** : GCP_PROJECT_ID, GCP_WORKLOAD_IDENTITY_PROVIDER, GCP_SERVICE_ACCOUNT, etc.
- [ ] **Donner acc√®s GCP √† Mohamed** : Storage Object Admin + BigQuery Data Editor + BigQuery Job User pour offre-ingestion
- [ ] **Int√©gration BigQuery** :
  - [ ] Ajouter d√©pendance `google-cloud-bigquery` aux services concern√©s
  - [ ] Cr√©er client BigQuery partag√© dans shared/
  - [ ] Adapter offre-ingestion pour √©crire dans silver.offers
  - [ ] Adapter offre-ingestion pour √©crire JSON bruts dans Cloud Storage bronze
  - [ ] Cr√©er sch√©mas BigQuery (skills, formations, languages) dans silver
  - [ ] Adapter matching pour lire depuis BigQuery silver
  - [ ] Cr√©er tables gold (daily_stats, skills_ranking)
  - [ ] Configurer credentials BigQuery dans docker-compose
  - [ ] Tester √©criture/lecture BigQuery
- [ ] **D√©ploiement initial VM** : SSH, clone repo, docker-compose up
- [ ] **Configurer domaine + HTTPS** : Caddy avec Let's Encrypt
- [ ] **Int√©gration LLM Google** : support Gemini/Vertex AI comme provider LLM alternatif (cv-ingestion, ai-assistant)
