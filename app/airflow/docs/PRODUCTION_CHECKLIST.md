# ‚úÖ Checklist Production - Airflow JobMatch

## üìã Pour les d√©veloppeurs

### 1Ô∏è‚É£ Pr√©requis syst√®me
- [ ] Docker et Docker Compose install√©s
- [ ] Git configur√©
- [ ] Minimum 4 GB RAM disponibles pour Docker
- [ ] Acc√®s au repository Git du projet
- [ ] Credentials GCP (fichier JSON service account)
- [ ] Credentials API France Travail (Client ID + Secret)

### 2Ô∏è‚É£ Setup initial (premi√®re fois)

```bash
# Cloner le projet
git clone <URL_DU_REPO>
cd jobmatch/app/airflow

# Configurer l'environnement
cp .env.example .env
nano .env  # Adapter avec VOS valeurs

# Variables OBLIGATOIRES √† modifier dans .env :
# - HOST_AIRFLOW_PATH : votre chemin absolu
# - AIRFLOW_UID : votre UID (echo $(id -u))
# - GOOGLE_APPLICATION_CREDENTIALS
# - SMTP_USER et SMTP_PASSWORD
# - FT_CLIENT_ID et FT_CLIENT_SECRET

# Ajouter les credentials GCP
mkdir -p ./credentials
cp /chemin/vers/votre-cle-gcp.json ./credentials/gcp-service-account-key.json
chmod 600 ./credentials/gcp-service-account-key.json

# Configurer offre-ingestion
cd ../offre-ingestion
cp .env.example .env
nano .env  # M√™mes valeurs que airflow/.env

mkdir -p ./credentials
cp /chemin/vers/votre-cle-gcp.json ./credentials/gcp-service-account-key.json
```

### 3Ô∏è‚É£ Build des images Docker

```bash
# Depuis la RACINE du projet (important pour la d√©pendance 'shared')
cd /chemin/vers/jobmatch

# Build de l'image offre-ingestion
docker build -f app/offre-ingestion/Dockerfile -t offre-ingestion-pipeline:latest .

# V√©rification
docker images | grep offre-ingestion
```

### 4Ô∏è‚É£ D√©marrage d'Airflow

```bash
cd app/airflow

# Permissions (Linux uniquement)
mkdir -p ./logs ./plugins
chmod -R 777 ./logs ./plugins

# Lancement
docker compose up -d

# V√©rification
docker compose ps
# Tous les services doivent √™tre UP et HEALTHY
```

### 5Ô∏è‚É£ Acc√®s et activation

```
URL: http://localhost:8080
Username: airflow
Password: airflow
```

1. Se connecter √† l'interface
2. Chercher le DAG `offre_ingestion_pipeline`
3. L'activer (toggle ON)
4. Tester avec le bouton ‚ñ∂Ô∏è (Play)

---

## üß™ Tests de validation

```bash
cd /chemin/vers/jobmatch/app/airflow

# 1. V√©rifier que les conteneurs sont UP
docker compose ps

# 2. V√©rifier que le DAG est charg√©
docker compose exec airflow-scheduler airflow dags list | grep offre_ingestion

# 3. V√©rifier l'acc√®s Docker depuis Airflow
docker compose exec airflow-scheduler docker ps

# 4. Test d'ex√©cution manuelle (optionnel, peut √™tre long)
docker compose exec airflow-scheduler airflow tasks test offre_ingestion_pipeline fetch_offers_to_gcs 2026-01-05
```

---

## üö® Probl√®mes courants

### "Permission denied" sur /var/run/docker.sock
```bash
sudo usermod -aG docker $USER
newgrp docker
```

### "Image offre-ingestion-pipeline not found"
```bash
# Rebuilder depuis la RACINE du projet
cd /chemin/vers/jobmatch
docker build -f app/offre-ingestion/Dockerfile -t offre-ingestion-pipeline:latest .
```

### Le DAG n'appara√Æt pas
```bash
# V√©rifier les logs du scheduler
docker compose logs airflow-scheduler --tail=100

# Recharger le DAG
docker compose restart airflow-scheduler
```

### Erreur "Credentials not found"
- V√©rifier que le chemin dans `.env` est correct
- V√©rifier que le fichier existe : `ls -la ./credentials/gcp-service-account-key.json`
- V√©rifier les permissions : `chmod 600 ./credentials/gcp-service-account-key.json`

---

## üîÑ Mise √† jour du code

Quand le code change :

```bash
cd /chemin/vers/jobmatch/app/airflow

# Arr√™ter Airflow
docker compose down

# Mettre √† jour le code
git pull

# Rebuilder les images si n√©cessaire
cd /chemin/vers/jobmatch
docker build -f app/offre-ingestion/Dockerfile -t offre-ingestion-pipeline:latest .

cd app/airflow
docker compose build

# Red√©marrer
docker compose up -d
```

---

## üìä Monitoring

### Via l'interface Web (recommand√©)
- http://localhost:8080
- Vue "Grid" : historique des ex√©cutions
- Vue "Graph" : visualisation du pipeline
- Vue "Logs" : logs d√©taill√©s par t√¢che

### Via CLI
```bash
# Logs en temps r√©el
docker compose logs -f airflow-scheduler

# √âtat du DAG
docker compose exec airflow-scheduler airflow dags state offre_ingestion_pipeline
```

---

## üõë Arr√™t et nettoyage

```bash
# Arr√™t propre
docker compose down

# Arr√™t avec suppression des volumes (‚ö†Ô∏è perte de donn√©es)
docker compose down -v

# Nettoyage des images Docker
docker system prune -a
```

---

## üìö Documentation

- [SETUP_GUIDE.md](./SETUP_GUIDE.md) : Guide d√©taill√© de setup
- [README.md](./README.md) : Vue d'ensemble du projet
- [offre-ingestion README](../offre-ingestion/README.md) : Documentation du pipeline

---

## üîê S√©curit√© - IMPORTANT

### ‚ö†Ô∏è Ne JAMAIS commiter :
- Le fichier `.env` (contient les secrets)
- Les fichiers dans `credentials/`
- Les fichiers `*.json` (sauf exemples)
- Les logs dans `logs/`

### ‚úÖ √Ä commiter :
- `.env.example` (template sans secrets)
- `docker-compose.yml`
- `Dockerfile`
- Les DAGs dans `dags/`
- La documentation

### üîí Pour la production :
- Changer les mots de passe par d√©faut dans `.env`
- Utiliser des secrets managers (Vault, GCP Secret Manager)
- Limiter les permissions du service account GCP
- Activer l'authentification RBAC dans Airflow
- Configurer HTTPS pour l'interface Web
