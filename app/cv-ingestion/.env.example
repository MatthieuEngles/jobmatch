# CV Ingestion Service Configuration

# LLM Provider - Supported types: openai, anthropic, ollama, openai_compatible
LLM_TYPE=openai
LLM_ENDPOINT=
LLM_API_KEY=sk-your-api-key
LLM_MODEL=gpt-4o-mini

# Examples:
# OpenAI:           LLM_TYPE=openai, LLM_MODEL=gpt-4o-mini
# Anthropic:        LLM_TYPE=anthropic, LLM_MODEL=claude-3-sonnet-20240229
# Ollama:           LLM_TYPE=ollama, LLM_MODEL=llama3, LLM_ENDPOINT=http://localhost:11434/v1
# vLLM/LocalAI:     LLM_TYPE=openai_compatible, LLM_ENDPOINT=http://localhost:8000/v1

# Processing
MAX_FILE_SIZE_MB=10
SUPPORTED_FORMATS=pdf,docx
EXTRACTION_TIMEOUT_SECONDS=120

# Debug
DEBUG=false
