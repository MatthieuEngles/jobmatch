# ğŸš€ ExÃ©cution du Pipeline avec Docker

## ğŸ“‹ PrÃ©requis

- Docker et Docker Compose installÃ©s
- Credentials GCP configurÃ©s
- Fichier `.env` Ã  la racine du service

## âš™ï¸ Configuration

### 1. CrÃ©er le fichier `.env`

```bash
cd app/offre-ingestion
cp .env.example .env
# Ã‰diter .env avec vos credentials
```

Contenu du `.env` :
```env
# GCP Configuration
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
GCP_PROJECT_ID=your-project-id
GCS_BUCKET_NAME=your-bucket
BIGQUERY_DATASET_SILVER=silver_dataset
BIGQUERY_DATASET_GOLD=gold_dataset

# France Travail API
FT_CLIENT_ID=your_client_id
FT_CLIENT_SECRET=your_client_secret
FT_SCOPE=list_of_scopes
FT_OAUTH_URL=the_oauth_url
FT_API_URL_BASE=the_api_base_url
FT_ROMECODES_PATH=path/to/romecodes.txt
```

## ğŸ—ï¸ Build de l'image

**Important** : Le build doit Ãªtre lancÃ© depuis la **racine du projet** pour accÃ©der au package `shared`.

```bash
# Depuis la racine du projet jobmatch
cd /path/to/jobmatch

# Build avec le contexte racine
docker build -f app/offre-ingestion/Dockerfile -t offre-ingestion-pipeline:latest .
```

## ğŸš€ ExÃ©cution du Pipeline

### Commandes individuelles

```bash
# Se placer dans le dossier du service
cd app/offre-ingestion

# 1ï¸âƒ£ Bronze : Fetch offres â†’ GCS
docker compose run --rm offre-ingestion fetch 2025-12-31

# 2ï¸âƒ£ Silver : GCS â†’ BigQuery (structuration)
docker compose run --rm offre-ingestion silver 2025-12-31

# 3ï¸âƒ£ Gold : Silver â†’ Gold (embeddings)
docker compose run --rm offre-ingestion gold 2025-12-31
```

### Pipeline complet

```bash
# ExÃ©cution sÃ©quentielle avec date spÃ©cifique
DATE="2025-12-31"
docker compose run --rm offre-ingestion fetch $DATE && \
docker compose run --rm offre-ingestion silver $DATE && \
docker compose run --rm offre-ingestion gold $DATE

# Ou avec la date de J-1 (par dÃ©faut)
docker compose run --rm offre-ingestion fetch && \
docker compose run --rm offre-ingestion silver && \
docker compose run --rm offre-ingestion gold
```

## ğŸ“Š Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   France    â”‚ API  â”‚   Bronze    â”‚ GCS  â”‚   Silver    â”‚ BQ   â”‚    Gold     â”‚
â”‚  Travail    â”‚â”€â”€â”€â”€â”€â–¶â”‚    Layer    â”‚â”€â”€â”€â”€â”€â–¶â”‚    Layer    â”‚â”€â”€â”€â”€â”€â–¶â”‚    Layer    â”‚
â”‚             â”‚      â”‚ (JSON brut) â”‚      â”‚ (StructurÃ©) â”‚      â”‚ (Embeddings)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     API                  GCS               BigQuery            BigQuery+AI
```

## ğŸ” VÃ©rification

### VÃ©rifier les logs Docker

```bash
# Logs d'un service
docker compose logs offre-ingestion

# Suivre les logs en temps rÃ©el
docker compose logs -f offre-ingestion
```

### VÃ©rifier les donnÃ©es GCS

```bash
# Liste les fichiers bronze
gsutil ls gs://your-bucket/bronze/

# Voir le contenu d'une date
gsutil ls gs://your-bucket/bronze/2025-12-31/
```

### VÃ©rifier les tables BigQuery

```bash
# Silver tables
bq ls silver_dataset

# Gold tables
bq ls gold_dataset

# Compter les offres dans Silver
bq query --use_legacy_sql=false \
  'SELECT COUNT(*) as total FROM `project.silver_dataset.offers`'
```

## âš ï¸ Notes importantes

- **Sans date** : Le pipeline traite automatiquement les donnÃ©es de J-1
- **Architecture mÃ©daillon** : Bronze (GCS) â†’ Silver (BigQuery) â†’ Gold (BigQuery + Embeddings)
- **Idempotence** : Chaque Ã©tape peut Ãªtre relancÃ©e sans risque de duplication
- **DÃ©pendances** : Chaque Ã©tape dÃ©pend de la prÃ©cÃ©dente (fetch â†’ silver â†’ gold)

## ğŸ› DÃ©pannage

### Erreur "No space left on device"

```bash
# Nettoyer les images et conteneurs inutilisÃ©s
docker system prune -a --volumes -f
```

### Erreur d'authentification GCP

```bash
# VÃ©rifier le fichier de credentials
cat credentials/gcp-service-account-key.json

# Tester l'authentification
docker compose run --rm offre-ingestion python -c "from google.cloud import storage; print(storage.Client())"
```

### Rebuild forcÃ©

```bash
# Rebuild sans cache
cd /path/to/jobmatch
docker build --no-cache -f app/offre-ingestion/Dockerfile -t offre-ingestion-pipeline:latest .
```
