services:
  gui:
    build:
      context: .
      dockerfile: app/gui/Dockerfile
    ports:
      - "${GUI_PORT}:8080"
    env_file:
      - .env
    environment:
      - ENV_MODE=${ENV_MODE}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - CV_INGESTION_URL=${CV_INGESTION_URL}
      - MATCHING_URL=${MATCHING_URL}
      - AI_ASSISTANT_URL=${AI_ASSISTANT_URL}
      - USE_MOCK_MATCHING=${USE_MOCK_MATCHING}
      - USE_SQLITE_OFFERS=${USE_SQLITE_OFFERS}
      - MATCHING_SERVICE_URL=${MATCHING_SERVICE_URL}
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - BIGQUERY_SILVER_DATASET=${BIGQUERY_SILVER_DATASET}
      - BIGQUERY_GOLD_DATASET=${BIGQUERY_GOLD_DATASET}
      # Auth via ADC (local/VM) or Workload Identity (CI/CD) - no JSON key needed
      - EMBEDDINGS_PROVIDER=${EMBEDDINGS_PROVIDER}
      - EMBEDDINGS_MODEL=${EMBEDDINGS_MODEL}
    depends_on:
      - db
    networks:
      - jobmatch-network

  cv-ingestion:
    build:
      context: .
      dockerfile: app/cv-ingestion/Dockerfile
    ports:
      - "${CV_INGESTION_PORT}:8081"
    env_file:
      - .env
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - LLM_TYPE=${LLM_TYPE}
      - LLM_ENDPOINT=${LLM_ENDPOINT}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - DEBUG=${DEBUG}
    networks:
      - jobmatch-network

  ai-assistant:
    build:
      context: .
      dockerfile: app/ai-assistant/Dockerfile
    ports:
      - "${AI_ASSISTANT_PORT}:8084"
    env_file:
      - .env
    environment:
      - DEBUG=${DEBUG}
      - LLM_TYPE=${LLM_TYPE}
      - LLM_ENDPOINT=${LLM_ENDPOINT}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
    networks:
      - jobmatch-network

  offre-ingestion:
    build:
      context: .
      dockerfile: app/offre-ingestion/Dockerfile
    ports:
      - "${OFFRE_INGESTION_PORT}:8082"
    env_file:
      - .env
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - FRANCE_TRAVAIL_API_KEY=${FRANCE_TRAVAIL_API_KEY}
    networks:
      - jobmatch-network

  matching:
    build:
      context: .
      dockerfile: app/matching/Dockerfile
    ports:
      - "${MATCHING_PORT}:8086"
    env_file:
      - .env
    volumes:
      - ${GCP_KEY_PATH}:/secrets/gcp/key.json:ro
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/secrets/gcp/key.json
      - DATABASE_URL=${DATABASE_URL}
      - CV_INGESTION_URL=${CV_INGESTION_URL}
      - OFFRE_INGESTION_URL=${OFFRE_INGESTION_URL}
      - JOB_OFFERS_DB_PATH=${JOB_OFFERS_DB_PATH}
      - GCP_PROJECT_ID=${GCP_PROJECT_ID_DTB}
      - MATCHING_PORT=${MATCHING_PORT}
    depends_on:
      - cv-ingestion
      - offre-ingestion
    networks:
      - jobmatch-network

  db:
    image: postgres:16-alpine
    ports:
      - "${DB_PORT}:5432"
    env_file:
      - .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - jobmatch-network

  redis:
    image: redis:7-alpine
    ports:
      - "${REDIS_PORT}:6379"
    networks:
      - jobmatch-network

  local-ollama:
    profiles:
      - ollama
      - full
    build:
      context: .
      dockerfile: app/local_ollama/Dockerfile
    ports:
      - "${OLLAMA_PORT}:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - jobmatch-network

networks:
  jobmatch-network:
    driver: bridge

volumes:
  postgres_data:
  ollama_data:
